# 5.4 Dischi

&nbsp;
&nbsp;
&nbsp;

*Hardware dei dischi*
====

Esistono molti tipi di dischi. I più comuni sono i dischi rigidi magnetici, caratterizzati dal fatto che le operazioni di lettura e scrittura sono ugualmente veloci, rendendoli l’ideale come memoria secondaria (per la paginazione, i file system, e così via). Array di questi dischi sono talvolta utilizzati per fornire memoria altamente affidabile. Diversi tipi di dischi ottici (DVD e Blu-ray) sono anch’essi importanti per la distribuzione di programmi, dati e filmati. Infine, i dischi allo stato solido sono sempre più comuni, perché sono veloci e non contengono parti in movimento. Nei paragrafi a seguire descriveremo prima l’hardware e poi il software di questi dispositivi.

&nbsp;
&nbsp;
&nbsp;

*Dischi magnetici*
====

I dischi magnetici sono organizzati in cilindri, ciascuno contenente tante tracce quante sono le testine impilate verticalmente. Le tracce sono divise in settori e il numero dei settori lungo la circonferenza va generalmente da 8 a 32 sui floppy disk, fino a parecchie centinaia sui dischi fissi. Il numero di testine varia da 1 a 16.

I dischi più vecchi hanno poca elettronica e portano un semplice flusso di bit in serie. Su questi dischi il controller esegue la maggior parte del lavoro. Sugli altri dischi, in particolare sugli IDE (integrated drive electronics) e sui SATA (serial ATA) è l’unità del disco stesso a contenere un microcontroller che svolge una parte considerevole del lavoro e permette al controller reale di inviare un insieme di comandi ad alto livello. Il controller spesso fa la cache delle tracce, il rimappaggio dei blocchi difettosi e molto altro.

Una caratteristica che ha importanti implicazioni per il driver del disco è la possibilità che un controller possa fare la ricerca su due o più unità allo stesso tempo. Queste ricerche sono conosciute con il nome di ricerche sovrapposte (overlapped seek). Mentre il controller e il software sono in attesa che si completi una ricerca su di un’unità, il controller può iniziare una ricerca su un’altra unità. Molti controller possono anche leggere o scrivere su un’unità mentre stanno eseguendo una ricerca su di una o più di una di loro, ma il controller di un floppy disk non è in grado di leggere o scrivere contemporaneamente su due unità allo stesso tempo. (Le operazioni di lettura e di scrittura richiedono che il controller muova i bit in una scala temporale di microsecondi, cosicché un trasferimento usa la maggior parte della sua potenza di elaborazione.) La situazione è diversa per i dischi rigidi con controller integrati e, in un sistema con uno o più di questi dischi, essi possono operare simultaneamente, quanto meno nel trasferire fra il disco e la memoria del buffer del controller. In ogni caso è possibile un solo trasferimento fra il controller e la memoria principale. La capacità di esecuzione di due o più operazioni nel medesimo istante può ridurre considerevolmente il tempo di accesso medio.

La Figura 5.18 confronta i parametri dei supporti di memorizzazione standard con i PC IBM originali, per mostrare quanto siano cambiati i dischi nel corso di trent’anni. È interessante notare che non tutti i parametri hanno avuto uno sviluppo così notevole. Il tempo medio di ricerca è migliorato di 9 volte, la velocità di trasferimento è migliorata di 16.000 volte, mentre la capacità è cresciuta di un fattore di 800.000. Questo modello ci mostra un miglioramento graduale delle componenti meccaniche, a fronte di una crescita molto più elevata della densità dei bit sulle superfici di registrazione.


Parametri del disco per il floppy disk del PC IBM originale a 360 KB e per il disco fisso Western Digital WD 3000 HLFS.

| **Parametro**                         	| **Floppy Disk IBM 360kb** 	| **Disco Fisso WD 3000 HLFS** 	|
|---------------------------------------	|---------------------------	|------------------------------	|
| Numero Cilindri                       	| 40                        	| 36.481                       	|
| Tracce per cilindro                   	| 2                         	| 255                          	|
| Settori per traccia                   	| 9                         	| 63 (media)                   	|
| Settori per disco                     	| 720                       	| 586.072.368                  	|
| Capacità del disco                    	| 360 KB                    	| 300 GB                       	|
| Tempo di ricerca (cilindri adiacenti) 	| 6 ms                      	| 0,7 ms                       	|
| Tempo di ricerca (situazione media)   	| 77 ms                     	| 4,3 ms                       	|
| Tempo di rotazione                    	| 200 ms                    	| 6 ms                         	|
| Tempo di stop/avvio del motore        	| 250 ms                    	| 1 ms                         	|
| Tempo di trasferire un settore        	| 22 ms                     	| 1 ns                         	|
|                                       	|                           	|                              	|

Un aspetto cui prestare attenzione nell’osservare le specifiche dei dischi fissi moderni è che la geometria specificata e usata dal software del driver è quasi sempre diversa dal formato fisico. Sui vecchi dischi il numero di settori per traccia era lo stesso per tutti i cilindri. I dischi moderni sono suddivisi in zone con più settori nelle zone esterne rispetto a quelle interne. La Figura 5.19(a) mostra un piccolo disco con due zone. La zona esterna ha 32 settori per traccia; quella interna ha 16 settori per traccia. Un disco reale, come il WD 18300, ha tipicamente 16 o più zone, con il numero di settori che aumenta di circa il 4% per zona, partendo dall’interno verso l’esterno.


(a) Geometria fisica di un disco con due zone. (b) Una possibile geometria virtuale per questo disco.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-19.png)

Per nascondere i dettagli di quanti settori abbia ogni traccia, la maggior parte dei dischi fissi moderni ha una geometria virtuale che viene presentata al sistema operativo. Il software è istruito per comportarsi come se ci fossero x cilindri, y testine e z settori per traccia. Il controller rimappa poi una richiesta per (x, y, z) nel cilindro, nella testina e nel settore reali. Una possibile geometria virtuale per il disco fisico della Figura 5.19(a) è mostrata nella Figura 5.19(b). In entrambi i casi il disco ha 192 settori, è solo la sistemazione pubblicata a essere differente da quella reale.

Per i PC i valori massimi di questi tre parametri (65535, 16 e 63) sono spesso dovuti alla ne­cessità della retrocompatibilità con i limiti dei PC IBM originali. Per specificare tali numeri su questa macchina erano usati campi fino a 16, 4 e 6 bit con cilin­dri e settori numerati partendo da 1 e le testine numerate a partire da 0. Con tali parame­tri e 512 byte per settore, la dimensione massima del disco raggiunge i 31,5 GB. Per supe­rare questo limite ora i di­schi moderni supportano un sistema chiamato indirizzamento ­logico dei blocchi (logical block addressing) in cui i settori dei dischi sono numerati consecutivamente partendo da 0, senza alcuna considerazione della geometria del disco.

&nbsp;
&nbsp;
&nbsp;

*RAID*
====

Le prestazioni delle CPU sono cresciute esponenzialmente negli ultimi dieci anni, quasi raddoppiando ogni 18 mesi. Non è stato così per le prestazioni dei dischi. Negli anni Settanta del secolo scorso i tempi di ricerca medi su un minicomputer andavano dai 50 ai 100 ms; oggi sono pochi ms. Nella maggior parte delle aziende nel settore automobilistico e aeronautico un fattore di crescita di prestazioni da 5 a 10 nel corso di 20 anni sarebbe considerato decisamente positivo (immaginate di riuscire a percorrere 200 km con un litro di benzina), mentre nell’industria dei computer sarebbe considerato imbarazzante. Il gap di prestazioni fra CPU e dischi ha continuato a crescere in questa direzione nel corso del tempo.

Come abbiamo visto, per velocizzare le prestazioni della CPU è stata sempre più utilizzata l’elaborazione parallela. Molti hanno pensato che il parallelismo dell’I/O potesse essere un’idea altrettanto buona. Nella loro pubblicazione del 1988, Patterson et al. suggerivano sei specifiche organizzazioni dei dischi che avrebbero potuto migliorarne le prestazioni e l’affidabilità (Patterson et al., 1988). Queste idee furono rapidamente adottate dall’industria e diedero luogo a una nuova classe di dispositivi di I/O chiamati RAID. Patterson et al. definirono il RAID come redundant array of inexpensive disks (array ridondante di dischi economici), ma l’industria ridefinì la “I” come “indipendent” (indipendenti) invece di “inexpensive” (forse perché così potevano guadagnarci di più). Poiché c’è sempre bisogno dell’alter ego negativo (come nel caso di RISC rispetto a CISC, sempre dovuto a Patterson), in questo caso il “cattivo” era lo SLED (single large expensive disk).

L’idea alla base del RAID è installare un contenitore pieno di dischi accanto al computer, solitamente un grosso server, sostituire la scheda controller dei dischi con un controller RAID, copiare i dati nel RAID e quindi continuare le normali operazioni. In altre parole un RAID verrebbe visto dal sistema operativo come uno SLED, ma con prestazioni migliori e maggiore affidabilità. Poiché i dischi SCSI hanno buone prestazioni, basso costo e capacità di poter avere fino a 15 dischi gestiti da un singolo controller, è naturale che la maggior parte dei RAID sia costituita da un controller RAID SCSI più uno stack di dischi SCSI che il sistema operativo vede come un unico grande disco. Oggi la maggior parte dei produttori offre dei RAID basati anche su SATA (molto meno costosi). In questo modo, per usare il RAID non è richiesto alcun cambiamento software, un punto di forza importante per far sì che questa soluzione fosse adottata da molti amministratori di sistema.

Oltre ad apparire al software come un disco singolo, al fine di permettere operazioni parallele i dati di tutti i RAID sono distribuiti su tutti i dischi. Per raggiungere tale scopo Patterson et al. lavorarono a diversi schemi, conosciuti come RAID dal livello 0 fino al livello 5. Esistono inoltre altri livelli minori che non prenderemo in esame. Il termine “livello” (level) è un termine improprio, visto che fra questi sei livelli non vi è alcuna gerarchia. Si tratta solo di sei diverse modalità di organizzazione.

Il RAID di livello 0 è illustrato nella Figura 5.20(a). Consiste nel vedere il singo­lo ­disco virtuale simulato dal RAID come se fosse diviso in strip (strisce) di k settori ciascuna, con lo strip 0 costituito dai settori da 0 a k – 1, lo strip 1 da quelli da k a 2k – 1 e così via. Per k = 1, ogni strip è un settore; per k = 2 uno strip è costituito da due settori, e così via. L’or­ganizzazione del RAID di livello 0 scrive strip consecutivi sull’unità in modalità round-robin, come descritto nella Figura 5.20(a) per un RAID con quattro unità disco.



RAID di livello da 0 a 5. I dischi di backup e di parità sono rappresentati in grigio.


![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-20.png)


Questa distribuzione dei dati su più unità è chiamata striping. Se per esempio il software invia un comando per leggere un blocco di dati che consiste di quattro strip consecutivi, il controller RAID dividerà questo comando in quattro comandi separati, uno per ciascuno dei quattro dischi, facendoli operare in parallelo. In questo modo abbiamo un I/O parallelo senza che il software ne sia a conoscenza.

Il RAID di livello 0 funziona meglio con richieste grandi. Se una richiesta è superiore al numero di unità moltiplicato per la dimensione dello strip, alcune unità riceveranno più richieste, cosicché quando termineranno la prima richiesta faranno partire la seconda. Sta al controller suddividere la richiesta e fornire i comandi adeguati al disco corretto nella giusta sequenza e poi assemblare correttamente in memoria i risultati. Le prestazioni sono eccellenti e l’implementazione è semplice.

Il RAID di livello 0 funziona peggio con i sistemi operativi che interrogano abitualmente un settore per volta: i risultati saranno corretti, ma senza parallelismo e quindi senza guadagno di prestazioni. Un altro svantaggio di questa organizzazione è che è potenzialmente meno affidabile rispetto a uno SLED. Se un RAID è composto da quattro dischi, ognuno con un tempo medio di errore (mean time to failure) di 20.000 ore, circa una volta ogni 5.000 ore un’unità andrà in errore e tutti i dati saranno persi completamente. Uno SLED con un tempo medio di errore di 20.000 ore sarebbe quattro volte più affidabile. Dato che in questo schema non è presente ridondanza, non è un vero e proprio RAID.

L’opzione successiva, il RAID di livello 1, mostrato nella Figura 5.20(b) è un vero RAID. Esso duplica tutti i dischi, con quattro dischi primari e quattro dischi di backup. In scrittura ogni strip è scritto due volte. In lettura può essere usata qualunque copia, distribuendo il carico su più unità. Di conseguenza le prestazioni in scrittura non migliorano, ma quelle in lettura possono essere fino a due volte meglio. La tolleranza agli errori (fault tolerance) è eccellente: in caso di guasto di un disco viene semplicemente usato l’altro. Il ripristino consiste nell’installare una nuova unità e nel copiare l’intero disco di backup su di essa.

Diversamente dai livelli 0 e 1, che lavorano con strip di settori, il RAID di livello 2 lavora sulla base delle parole, eventualmente anche sulla base dei byte. Immaginate che ciascun byte del singolo disco virtuale sia suddiviso in una coppia di due parti da 4 bit, quin­di aggiungiamo a ciascuno un codice di Hamming a formare una parola di 7 bit, in cui i bit 1, 2 e 4 siano i bit di parità. Si immagini inoltre che le sette unità della Figura 5.20(c) siano sincronizzate in termini di posizione del braccio e della testina. Sarebbe quindi possibile scrivere la parola di 7 bit codificata con il codice di Hamming sulle sette unità, un bit ciascuna. Il computer Thinking Machines CM-2 usava questo schema, prendendo parole di dati a 32 bit e aggiungendo i 6 bit di parità per formare una parola Hamming a 38 bit, più un bit extra per la parità della parola, distribuendo ciascuna parola su 39 unità disco. Il throughput totale era immenso, dato che nel tempo di un settore poteva scrivere l’equivalente di 32 settori di dati. Inoltre la perdita di un’unità non causava problemi, poiché significava perdere 1 bit in ciascuna parola da 39 bit letta, un fatto che il codice di Hamming può gestire in modo trasparente. Il lato negativo di questo schema sta nella necessità di avere tutte le unità sincronizzate dal punto di vista rotazionale e nel fatto che ha senso solo con un numero considerevole di unità (anche con 32 unità dati e 6 unità di parità, l’overhead è del 19%). Impegna inoltre parecchio il controller, dato che deve fare un controllo del codice di Hamming ogni volta che viene letto un bit.

Il RAID di livello 3 è una versione semplificata del RAID di livello 2. È illustrato nella Figura 5.20(d). In questo caso è calcolato un singolo bit di parità per ogni parola dati e scritto in un’unità di parità. Come nel RAID di livello 2, le unità devono essere perfettamente sincronizzate, poiché le singole parole dati sono distribuite su molteplici unità.

Di primo acchito potrebbe sembrare che un singolo bit di parità consenta solo la rilevazione degli errori e non la loro correzione. Nel caso di errori casuali non rilevati questa osservazione è vera, ma nel caso di crash dell’unità fornisce una completa correzione degli errori a 1 bit, poiché la posizione del bit guasto è conosciuta. Se l’unità ha un crash, il controller fa semplicemente finta che tutti i suoi bit siano 0. Se una parola ha un errore di parità, il bit dall’unità crollata avrebbe dovuto essere 1 e così può essere corretto. Sebbene sia il RAID di livello 2 sia quello di livello 3 offrano velocità di trasmissione dati molto alte, il numero di richieste gestibili di I/O separati per secondo non è maggiore di quello di un’unità singola.

I RAID di livello 4 e di livello 5 funzionano ancora a strip, non a parole individuali con la parità e non necessitano di sincronizzazione delle unità. Il RAID di livello 4 [vedi Figura 5.20(e)] è come il RAID di livello 0, con parità strip-per-strip scritta su un’unità extra. Per esempio, se ogni strip è lungo k byte, viene eseguito l’or esclusivo di tutti gli strip, risultando in uno strip di parità lungo k byte. Se si rompe un’unità, i byte persi possono essere ricalcolati a partire dall’unità di parità, leggendo l’intero insieme di dischi.

Questo schema protegge dalla perdita di un’unità, ma ha prestazioni scadenti per piccoli aggiornamenti. Se viene cambiato un settore è necessario leggere tutte le unità al fine di ricalcolare la parità, che deve poi essere riscritta. In alternativa può leggere i dati del vecchio utente e i dati della vecchia parità e ricostruire la nuova parità a partire da loro. Anche con questa ottimizzazione, un piccolo aggiornamento richiede due letture e due operazioni di scrittura.

A causa del suo intenso uso, l’unità di parità può diventare un collo di bottiglia, eliminato dal RAID di livello 5 distribuendo i bit di parità uniformemente su tutte le unità, in stile round-robin, come illustrato dalla Figura 5.20(f). Tuttavia la ricostruzione di un’unità nell’evenienza di un suo crash è un procedimento complesso.

Il RAID di livello 6 è simile al RAID di livello 5, a parte il fatto che si utilizza un blocco di parità aggiuntivo; in altre parole, si fa uno striping dei dati su tutti i dischi con due blocchi di parità invece di uno solo. Come risultato, le operazioni di scrittura sono un po’ più costose a causa dei calcoli della parità, ma le letture non hanno svantaggi prestazionali. Inoltre, offre una maggiore affidabilità (provate a immaginare che cosa succederebbe se RAID 5 incontrasse un blocco rovinato mentre sta ricostruendo l’array corrispondente).

&nbsp;
&nbsp;
&nbsp;

*Formattazione dei dischi*
====

Un disco rigido è composto da una pila di piatti di alluminio, di lega o di vetro da 5,25 pollici o 3,5 pollici di diametro (o 2,5 pollici sui computer portatili). Su ciascun piatto è depositato uno strato sottile di ossido metallico magnetizzabile. Dopo la produzione, sul disco non c’è alcuna informazione di alcun genere. Prima dell’uso ciascun piatto deve sottostare a una formattazione a basso livello eseguita via software. Il formato consiste di una serie di tracce concentriche, ognuna contenente un certo numero di settori, con dei piccoli spazi fra di loro. Il formato di un settore è mostrato nella Figura 5.21.



Un settore di un disco.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-25.png)

Il preambolo inizia con un determinato schema di bit che permette all’hardware di riconoscere l’inizio del settore. Contiene inoltre il cilindro e i numeri dei settori e qualche altra informazione. La dimensione della parte dei dati è determinata dal programma di formattazione a basso livello. La maggior parte dei dischi usa settori da 512 byte. Il campo ECC contiene informazioni ridondanti che possono essere usate per ripristinare eventuali errori di lettura. La dimensione e il contenuto di questo campo variano da produttore a produttore, a seconda di quanto spazio del disco il progettista lascia al fine di garantire un’alta affidabilità e di quanto sia complesso il codice ECC che il controller deve gestire. Non è raro che il campo ECC sia di 16 byte. Inoltre tutti i dischi fissi hanno allocato un certo nume­ro di settori di riserva da usare in sostituzione di settori che presentino un difetto di ­produzione.

La posizione del settore 0 su ciascuna traccia è spostata di un certo offset rispetto alla traccia precedente, quando è definita la formattazione a basso livello. Questo offset, chiama­to cylinder skew (pendenza del cilindro), serve a migliorare le prestazioni. L’idea è quel­la di consentire al disco di leggere tracce molteplici in un’operazione continua senza perdere dati. La natura del problema è ricavabile dalla Figura 5.19(a). Supponete che una richiesta abbia bisogno di 18 settori a partire dal settore 0 sulla traccia più interna. La lettura dei primi 16 settori richiede una rotazione del disco, ma serve una ricerca per posizionarsi sulla nuova traccia per prendere il settore 17. Nel mentre che la testina si è mossa di una traccia, il settore 0 è ruotato dietro la testina: quindi serve un’intera rotazione prima che vi ripassi. Questo problema è completamente risolto con l’offest dei settori mostrato nella Figura 5.22.



Illustrazione del cylinder skew.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-26.png)

La dimensione del cylinder skew dipende dalla geometria dell’unità. Per esempio, un’unità da 10.000 RPM (giri al minuto) ruota in 6 ms. Se una traccia contiene 300 settori, sotto la testina passa un nuovo settore ogni 20 s. Se il tempo di una ricerca traccia per traccia è di 800 s, durante la ricerca passeranno 40 settori, dunque il cylinder skew sarebbe di 40 settori, invece che di tre settori come mostrato nella Figura 5.23. Vale la pena menzionare che anche lo scambio delle testine comporta un certo tempo finito, dunque vi è anche un head skew come per i cilindri, sebbene non sia molto grande.



(a) Nessun interleaving. (b) Interleaving singolo. (c) Interleaving doppio.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-27.png)


Il risultato della formattazione a basso livello è una riduzione della capacità del disco, a seconda delle dimensioni del preambolo, dello spazio fra i settori e dell’ECC, così come in base al numero dei settori di scorta riservati. Spesso la capacità di un disco formattato si riduce di circa il 20% rispetto allo spazio non formattato. I settori di scorta non sono conteggiati nella capacità formattata, così tutti i dischi di un determinato tipo hanno esattamente la stessa capacità quando sono consegnati, indipendentemente da quanti settori difettosi abbiano effettivamente (se il numero di settori difettosi è superiore al numero di settori di scorta il disco è respinto e non viene consegnato).

C’è una discreta confusione riguardo la capacità dei dischi, poiché molti produttori dichiarano la capacità non formattata per far sembrare i dischi più grandi di quanto lo siano effettivamente. Considerate per esempio un disco la cui capacità, non formattata, sia 200  109 byte: potrebbe essere venduto come un disco da 200 GB. Tuttavia, dopo la formattazione probabilmente sarebbero disponibili per i dati solo 170  109 byte. Ad aggiungere confusione ci si metterebbe anche il sistema operativo che, con tutta probabilità, riporterebbe questa capacità come 158 GB, non 170 GB, dato che il software considera un 1 GB come 230 (1.073.741.824) byte e non 109 (1.000.000.000) byte.

A peggiorare la situazione ci si mette anche il mondo delle comunicazioni dati, nel cui ambito 1 Gbps significa 1.000.000.000 bit/s poiché il prefisso giga significa effettivamente 109 (un chilometro misura 1000 metri e non 1024). Solo nel caso della memoria e delle ­dimensioni dei dischi i termini kilo, mega, giga e tera significano rispettivamente 210, 220, 230 e 240.

La formattazione influisce anche sulle prestazioni. Se un disco da 10.000 RPM ha 300 settori per traccia di 512 byte ciascuno, impiega 6 ms a leggere i 153.600 byte di una traccia, a una velocità di 25.600.000 byte/s o 24,4 MB/s. Non è possibile andar più veloci, a prescindere dal tipo d’interfaccia, anche con un’interfaccia SCSI da 80 MB/s o 160 MB/s.

Effettivamente la lettura continua richiede a questa velocità un grande buffer nel controller. Considerate per esempio un controller con un buffer di un settore a cui sia stato dato un comando di lettura di due settori consecutivi. Dopo la lettura del primo settore e il calcolo dell’ECC, i dati devono essere trasferiti in memoria principale. Durante questo trasferimento, il settore seguente sarà letto dalla testina. Una volta completata la copia, il controller dovrà aspettare almeno un intero periodo di rotazione prima che arrivi il secondo settore.

Questo problema può essere eliminato numerando i settori in modalità interlacciata nel formattare il disco. Nella Figura 5.23(a) vediamo la numerazione classica (ignorando il ­cylinder skew). Nella Figura 5.23(b) si vede un interleaving singolo, che dà al controller un po’ di respiro fra due settori consecutivi, in modo da copiare il buffer in memoria principale.

Se il processo di copia è molto lento, allora può rendersi necessario l’interleaving doppio della Figura 5.23(c). Se il controller ha un buffer di un solo settore, non importa se la copia dal buffer alla memoria principale è fatta dal controller, dalla CPU principale o dal chip del DMA; impiega sempre lo stesso tempo. Per evitare la necessità dell’interleaving, il controller dovrebbe poter bufferizzare un’intera traccia. Molti controller moderni lo fanno.

Dopo la formattazione a basso livello il disco viene partizionato. Ogni partizione è vista logicamente come un disco separato. Le partizioni servono per consentire la coesistenza di diversi sistemi operativi. In alcuni casi una partizione può essere usata per lo swapping. Sui processori x86 e sulla maggior parte dei computer il settore 0 contiene il master boot record (MBR) contenente una parte del codice sorgente più, in fondo, la tabella delle partizioni. L’MBR, e di conseguenza il supporto alle tabelle di partizione, ha visto la luce nei primi PC IBM nel 1983, per supportare i dischi rigidi, per l’epoca giganteschi, da 10 MB del PC-XT. Da allora, i dischi sono diventati un po’ più grandini. Poiché le voci delle partizioni nell’MBR sono limitate a 32 bit, la dimensione massima di un disco che può essere supportata con settori da 512 byte è di 2 TB. Per questo motivo, la maggior parte dei sistemi operativi supportano oggi anche la nuova GPT (GUID partition table), che supporta dimensioni del disco fino a 9,4 ZB (9.444.732.965.739.290.426.880 byte). Al momento della stesura di questo libro, è una dimensione ragguardevole.

La tabella delle partizioni fornisce il settore di avvio e la dimensione di ciascuna partizione. Sui processori x86 la tabella delle partizioni può contenerne sino a quattro. Se sono tutte per Windows saranno chiamate C:, D:, E: ed F: e trattate come dischi separati. Se tre di loro sono per Windows e una per UNIX saranno chiamate C:, D: ed E: e, se si aggiunge una chiavetta USB, il suo nome sarà F:. Perché sia possibile avviare il sistema da disco fisso serve che una partizione sia contrassegnata nella tabella delle partizioni come attiva.

Il passaggio finale nella preparazione all’uso di un disco è eseguire una formattazione ad alto livello di ciascuna partizione (separatamente). Questa operazione stabilisce un blocco di avvio, l’amministrazione dello spazio di memorizzazione libero (elenco dei blocchi liberi o bitmap), la directory principale (root) e un file system (vuoto). Mette, inoltre, un codice nella tabella delle partizioni indicando quale file system sia utilizzato nella partizione, dato che molti sistemi operativi supportano molteplici file system incompatibili (per ragioni storiche). A questo punto il sistema può essere avviato.

Una volta acceso il computer, inizialmente parte il BIOS che poi legge il master boot record e vi si posiziona. Questo programma di avvio controlla poi quale partizione è attiva. Legge quindi il boot record di questa partizione e la fa partire. Il boot record contiene un piccolo programma che in generale carica un programma di avvio più grande, che cerca il file system per trovare il kernel del sistema operativo. Quel programma viene caricato in memoria ed eseguito.

&nbsp;
&nbsp;
&nbsp;

*Algoritmi di scheduling del braccio del disco*
====

In questo paragrafo analizzeremo alcune questioni generali relative ai driver dei dischi. Per prima cosa, considerate quanto tempo serve per la lettura o la scrittura di un blocco del disco.

Il tempo richiesto è determinato da tre fattori:

-   Il tempo di ricerca (il tempo per muovere il braccio al giusto cilindro);

-   Il ritardo rotazionale (il tempo affinché il settore giusto ruoti sotto la testina);

-   Il tempo effettivo di trasferimento dei dati.

Per la maggior parte dei dischi, il tempo di ricerca è decisamente maggiore degli altri due, cosicché la riduzione del tempo medio di ricerca migliora sostanzialmente le prestazioni del sistema. Se il driver del disco accetta una richiesta per volta e le esegue nello stesso ordine, cioè first-come, first-served (FCFS – “la prima che arriva è la prima a essere servita”), c’è ben poco da fare per ottimizzare il tempo di ricerca. È tuttavia possibile una diversa strategia quando il disco è utilizzato frequentemente. È probabile che, mentre il braccio sta compiendo una ricerca sulla base di una richiesta, altri processi generino altre richieste per il disco. Molti driver dei dischi mantengono una tabella, indicizzata per numero di cilindro, con tutte le richieste in attesa di ciascun cilindro, unite in una lista collegata alla testa delle voci della ­tabella.

Dato questo tipo di struttura dei dati, è possibile migliorare l’algoritmo di scheduling first-come, first-served. Per vedere in che modo, considerate un disco immaginario con 40 cilindri. Arriva una richiesta di lettura di un blocco sul cilindro 11. Mentre è in corso la ricerca del cilindro 11, arrivano nuove richieste dei cilindri 1, 36, 16, 34, 9 e 12, in quest’ordine. Sono inseriti nella tabella delle richieste in attesa, con una lista distinta per ciascun cilindro. Le richieste sono mostrate nella Figura 5.24.



L’algoritmo di scheduling del disco Shortest Seek First (SSF).

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-28.png)

Al termine della richiesta attuale (per il cilindro 11), il driver deve scegliere quale richiesta gestire come successiva. Se usasse l’FCFS come cilindro successivo avrebbe l’1, poi il 36 e così via. Questo algoritmo richiederebbe rispettivamente movimenti del braccio di 10, 35, 20, 18, 25 e 3 cilindri, per un totale di 111.

In alternativa, per ridurre al minimo il tempo di ricerca potrebbe sempre gestire come richiesta seguente la più vicina. Date le richieste della Figura 5.24, la sequenza è 12, 9, 16, 1, 34 e 36, illustrate nella Figura 5.24 dalla linea a zig zag alla base. Con questa sequenza gli spostamenti del braccio sono 1, 3, 7, 15, 33 e 2, per un totale di 61 cilindri. Questo algoritmo, shortest seek first (SSF – “la ricerca più breve per prima”), riduce lo spostamento totale del braccio quasi della metà in confronto all’FCFS.

Sfortunatamente l’SSF comporta un problema. Supponete che continuino ad arrivare più richieste durante il processo di quelle della Figura 5.24. Se, per esempio, dopo essere andato al cilindro 16, giunge una nuova richiesta per il cilindro 8, quella richiesta avrà priorità rispetto a quella del cilindro 1. Se arriva poi una richiesta del cilindro 13, il braccio vi si porterà escludendo di nuovo il cilindro 1. Con un disco che subisce un forte carico di lavoro, il braccio avrà la tendenza a restare per la maggior parte del tempo nel mezzo del disco, pertanto le richieste a entrambi gli estremi dovranno aspettare finché una fluttuazione statistica del carico di lavoro porterà a non avere richieste nel mezzo. Le richieste lontane dal centro avranno un servizio scadente. In questo caso gli obiettivi di un tempo di risposta basso e di imparzialità sono in contrasto.

Anche gli edifici alti hanno a che fare con questo problema. Il problema dello ­scheduling di un ascensore in un edificio con tanti piani è simile a quello del braccio di un disco. Arrivano continuamente richieste che chiamano a caso l’ascensore ai piani (i cilindri). Il computer che fa andare l’ascensore potrebbe facilmente tener traccia della sequenza delle richieste in cui gli utenti hanno premuto il pulsante di chiamata e servirli secondo l’FCFS o l’SSF.

Per trovare un punto d’incontro nell’eterno conflitto tra efficienza e imparzialità, la mag­gior parte degli ascensori usa tuttavia un algoritmo diverso: continuano a muoversi in una direzione finché non vi sono più richieste inevase in quella direzione, quindi cambiano direzione. Questo algoritmo, noto sia nel mondo dei dischi sia in quello degli ascensori con il nome di algoritmo dell’ascensore (elevator algorithm), richiede al software di gestire un bit: il bit della direzione attuale, UP o DOWN. Al termine di una richiesta, il driver del disco o dell’ascensore controlla il bit. Se è UP, il braccio o la cabina sono spostati alla richiesta successiva in attesa verso l’alto. Se non vi sono richieste in attesa più in alto allora viene invertito il bit della direzione. Quando il bit è impostato a DOWN, lo spostamento è nella posizione successiva inferiore richiesta, qualora ve ne sia una.

La Figura 5.25 mostra l’algoritmo dell’ascensore usando le stesse sette richieste della Figura 5.24, considerando che il bit della direzione sia inizialmente UP. L’ordine in cui sono serviti i cilindri è 12, 16, 34, 36, 9 e 1, il che comporta spostamenti del braccio di 1, 4, 18, 2, 27 e 8 cilindri, per un totale di 60. In questa situazione l’algoritmo dell’ascensore è leggermente migliore dell’SSF, sebbene in genere sia peggiore. Una caratteristica simpatica dell’algoritmo dell’ascensore è che, data una qualunque raccolta di richieste, il limite superiore dello spostamento massimo è fisso: è due volte il numero dei cilindri.



L’algoritmo dell’ascensore per lo scheduling delle richieste del disco.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-29.png)

Una piccola modifica di questo algoritmo che porta a una leggera variazione sui tempi di risposta (Teory, 1972) è quella di muoversi sempre nella stessa direzione. Quando è stata servita la richiesta con il numero più alto di cilindro, il braccio riparte dalla richiesta con il numero di cilindro inferiore e continua a muoversi in quella direzione. In effetti è come se il numero di cilindro più basso fosse sopra il numero di cilindro più alto.

Alcuni controller dei dischi forniscono al software un modo per controllare il settore attualmente sotto la testina. Con questo tipo di controller è possibile un’altra ottimizzazione. Se ci sono due o più richieste per il medesimo settore, il driver può inviare la richiesta successiva al settore più vicino a dove si trova in quel momento la testina. Notate che quando in un cilindro sono presenti più tracce, le richieste consecutive possono riguardare tracce diverse senza alcuna penalizzazione. Il controller può selezionare una qualsiasi delle sue testine quasi istantaneamente (la selezione delle testine non implica alcun movimento del braccio, né alcun ritardo rotazionale).

Se il disco ha la proprietà di avere un tempo di ricerca molto più veloce del ritar­do rotazionale dovrebbe essere usata una diversa ottimizzazione. Le richieste in atte­sa dovrebbero essere ordinate per numero di settore: appena il settore successivo sta per ­passare sotto la testina, il braccio dovrebbe sfrecciare alla traccia opportuna per leggerla o scriverla.

Con un disco rigido moderno la ricerca e il ritardo rotazionale sono così predominanti sulle prestazioni che la lettura di uno o due settori per volta è molto inefficiente. Per questo motivo molti controller dei dischi leggono e gestiscono la cache di più settori, anche quando ne è richiesto uno solo. Qualunque richiesta di lettura di un settore tipicamente causa la lettura di quel settore e di buona parte della traccia attuale, a seconda di quanta cache è disponibile nella memoria del controller. Per esempio, il disco descritto nel­la Figura 5.18 ha 4 MB di cache. L’uso della cache è determinato dinamicamente dal controller. Nella sua modalità più semplice, la cache è divisa in due parti, una per la lettura e l’altra per la scrittura. Se una lettura successiva può essere esaudita dalla cache del controller, questo può restituire i dati immediatamente.

Vale la pena notare che la cache del controller del disco è completamente indipendente dalla cache del sistema operativo. La cache del controller tiene abitualmente i blocchi che non sono stati richiesti, ma che è stato conveniente leggere, dato che si trovavano a passare sotto la testina come effetto di qualche altra lettura; al contrario, qualunque altra cache gestita dal sistema operativo è composta da blocchi esplicitamente letti e che il sistema operativo ipotizza possano essere ancora necessari nel breve termine (per esempio un blocco del disco contenente un blocco di directory).

Quando sono presenti molti dischi sul medesimo controller, il sistema operativo dovrebbe mantenere una tabella delle richieste in attesa separata per ciascun disco. Ogni volta che il disco è inattivo, dovrebbe essere inviata una ricerca per muoverne il braccio verso quel cilindro dove sarà necessario successivamente (dando per scontato che il controller permetta ricerche sovrapposte). Quando finisce il trasferimento corrente può essere fatto un controllo per verificare se qualcuno dei dischi sia posizionato sul corretto cilindro. Se uno o più lo sono, il successivo trasferimento sarà uno di questi, già sul cilindro giusto. Se nessuno braccio è nel punto giusto il driver dovrebbe inviare una nuova ricerca sul disco che ha appena terminato il trasferimento e attendere sino all’interrupt successivo per vedere quale braccio raggiunga per primo la propria destinazione.

È importante capire che tutti gli algoritmi di scheduling del disco precedentemente descritti danno tacitamente per scontato che la geometria reale del disco sia la stessa di quella virtuale. Nel caso non lo sia, le richieste di scheduling del disco non hanno senso, poiché il sistema operativo non può realmente indicare se il cilindro 40 o il cilindro 200 sia quello più vicino al cilindro 39. D’altra parte, se il controller del disco può accettare più richieste in attesa, può usare internamente questi algoritmi di scheduling. In questo caso gli algoritmi restano validi, ma un livello più in basso, all’interno del controller.

&nbsp;
&nbsp;
&nbsp;

*Gestione degli errori*
====

I produttori di dischi si spingono sempre più oltre ai limiti della tecnologia, incrementando le densità lineari dei bit. Una traccia circa alla metà di un disco da 5,25 pollici ha una circonferenza di circa 300 mm. Se una traccia contiene 300 settori di 512 byte, la densità di registrazione lineare può essere circa di 5.000 bit al millimetro, tenendo conto del fatto che un po’ di spazio viene perso tra preamboli, ECC e spazi fra i settori. La registrazione di 5.000 bit/mm richiede un substrato estremamente uniforme e un rivestimento di ossido molto sottile. Sfortunatamente è impossibile produrre un disco con queste specifiche senza alcun difetto. Appena la tecnologia di produzione è arrivata a poter operare perfettamente con queste densità, ecco che i progettisti dei dischi sono passati a densità superiori, per incrementare le capacità. E nel farlo si reintroducono alcuni difetti.

I difetti di produzione presentano settori difettosi (bad sectors) ossia settori che non rileggono correttamente il valore che vi è appena stato scritto. Se si tratta di un errore molto piccolo, diciamo di pochi bit, è possibile utilizzare il settore difettoso e far sì che l’ECC corregga ogni volta gli errori. Se il difetto è più grande, non può essere mascherato.

Gli approcci generali ai blocchi difettosi sono due: trattarli a livello di controller oppure a livello di sistema operativo. Nel primo approccio, prima che il disco esca dalla fabbrica, viene verificato e viene scritta una lista dei settori difettosi sul disco. Ciascuno di questi è sostituito da uno dei settori di riserva.

I modi per effettuare questa sostituzione sono due. Nella Figura 5.26(a) analizziamo u­na singola traccia di un disco con 30 settori dati e due di riserva. Il settore 7 è difettoso. Quel­lo che il controller può fare è rimappare uno dei settori di riserva come settore 7, come mostra la Figura 5.26(b). L’altro modo è far scorrere tutti i settori in su di uno, come illustrato nella Figura 5.26(c). In entrambi i casi il controller deve sapere di quale settore si tratta. Esso può tenere traccia di questa informazione attraverso tabelle interne (una per traccia) o riscrivendo i preamboli per assegnare i numeri di settore rimappati. Se sono riscritti i preamboli, il metodo della Figura 5.26(c) causa più lavoro (dato che devono essere riscritti 23 preamboli), ma alla fine dà migliori prestazioni, visto che un’intera traccia può essere ancora letta in una rotazione.



(a) Una traccia del disco con un settore difettoso. (b) Sostituzione del settore difettoso con uno di riserva. (c) Spostamento di tutti i settori per saltare quello difettoso.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-30.png)


Gli errori possono anche svilupparsi durante la normale operatività, dopo l’installazione del disco. La prima linea difensiva nel fronteggiare un errore che l’ECC non gestisce è semplicemente provare la rilettura. Alcuni errori sono passeggeri, cioè sono causati da granelli di polvere sotto la testina e se ne vanno al secondo tentativo. Se il controller rileva che sta riscontrando ripetuti errori in un determinato settore, può scambiarlo con un settore di riserva prima che sia definitivamente defunto. In questo modo non si perdono dati e sia il sistema operativo sia l’utente non notano il problema. Di solito deve essere usato il metodo della Figura 5.26(b) poiché gli altri settori ora potrebbero contenere dei dati. L’uso del metodo della Figura 5.26(c) richiederebbe non solo la riscrittura dei preamboli, ma anche la copia dei dati stessi.

Abbiamo detto che ci sono due modi per gestire gli errori: trattarli a livello di controller o a livello di sistema operativo. Se il controller non ha la possibilità di rimappare in modo trasparente i settori come abbiamo detto, il sistema operativo deve riuscire a fare la stessa cosa via software. Questo significa che deve prima acquisire un elenco di settori difettosi, sia leggendoli dal disco sia facendo semplicemente il test all’intero disco. Una volta saputo quali sono i settori difettosi, può costruire le tabelle di rimappaggio. Se il sistema operativo vuole usare l’approccio della Figura 5.26(c), deve far scalare i dati dei settori da 7 a 29 in su di un settore.

Se è il sistema operativo che gestisce il rimappaggio, deve accertarsi che non vi siano settori difettosi in alcun file e anche nella lista dei blocchi liberi o nella bitmap. Un modo per farlo è creare un file segreto composto da tutti i settori difettosi. Se questo file non è inserito nel file system, gli utenti non potranno accidentalmente leggerlo (o peggio cancellarlo).

C’è tuttavia ancora un altro problema, quello dei backup. Se il backup del disco è eseguito file per file, è importante che l’utility di backup non provi a copiare il file dei blocchi difettosi. Per prevenirlo, il sistema operativo deve nascondere il file dei blocchi difettosi così bene che nemmeno un’utility di backup possa trovarlo. Se il backup del disco è fatto setto­re per settore diventa difficile, se non impossibile, prevenire gli errori di lettura durante il backup. La sola speranza è che il programma sia abbastanza intelligente da proseguire dopo dieci tentativi falliti di lettura e proceda con il settore successivo.

I settori difettosi non sono l’unica fonte di errori. Possono anche accadere errori di lettura dovuti a problemi meccanici del braccio. Per eseguire una ricerca vengono inviati al motore del braccio una serie di impulsi, uno per cilindro, per muovere il braccio al nuovo cilindro. Quando il braccio raggiunge la sua destinazione, il controller legge il numero di cilindro effettivo dal preambolo del settore successivo. Se il braccio è nel posto sbagliato, abbiamo un errore di ricerca.

La maggior parte dei controller dei dischi fissi corregge gli errori di ricerca in automatico, ma la maggior parte dei controller dei floppy disk degli anni Ottanta e Novanta del secolo scorso imposta semplicemente un bit di errore e lascia il resto al driver. Il driver gestisce questo errore inviando un comando di recalibrate, per muovere il braccio il più lontano possibile e resettare la cognizione interna del controller riguardo il cilindro 0. Di solito questo risolve il problema, altrimenti bisogna riparare l’unità.

Come abbiamo visto il controller è davvero un piccolo computer specializzato, completo di software, variabili, buffer e occasionalmente errori. Talvolta una sequenza inusuale di eventi, come un interrupt su un’unità che avviene contemporaneamente a un comando di recalibrate per un altro disco scatena un errore e fa sì che il controller entri in un circolo vizioso o perda traccia di quanto sta facendo.

I progettisti dei controller di solito pensano al peggio e forniscono sul chip un pin che, quando utilizzato, forza il controller a dimenticare quanto stava facendo e a resettarsi da solo. Se fallisce tutto, il driver del disco può impostare un bit per richiamare questo segnale e resettare il controller. Se anche questo non aiuta allora tutto quello che il driver può fare è stampare un messaggio e rinunciare. La ricalibrazione di un disco fa un rumore curioso, ma normalmente non crea problemi. C’è tuttavia una situazione in cui la ricalibrazione è un problema serio: i sistemi con vincoli real-time. Quando un video è eseguito da disco rigido o dei file sono masterizzati da disco rigido su Blu-ray, è fondamentale che i bit arrivino dal disco fisso a velocità costante. In queste circostanze, la ricalibrazione inserisce degli intervalli nel flusso dei bit ed è perciò inaccettibile. Per queste applicazioni sono disponibili delle unità speciali, chiamate AV disk (audio visual disks – dischi audio visuali).

Una dimostrazione estremamente convincente di ciò che sono diventati i controller del disco più avanzati è stata data dall’hacker danese Jeroen Domburg, che è penetrato nel controller di un disco rigido moderno per fargli eseguire codice personalizzato. Si è quindi scoperto che il controller del disco è fornito di un processore ARM multicore (!) piuttosto potente e ha risorse sufficienti per eseguire Linux. Se un malintenzionato riuscisse a penetrare in questo modo in un disco rigido, potrebbe essere in grado di visualizzare e modificare tutti i dati che vengono trasferiti da e verso il disco rigido. Anche reinstallare da zero il sistema operativo non eliminerebbe l’infezione, perché sarebbe il controller del disco stesso a fungere da software malevolo, come backdoor permanente. In alternativa, è possibile mettere insieme un gruppo di dischi rigidi rotti prendendoli in un centro di riciclo e costruire un cluster computer senza spendere un centesimo.

&nbsp;
&nbsp;
&nbsp;

*Memoria stabile*
====

Come abbiamo visto, i dischi talvolta commettono degli errori. Settori buoni possono rivelarsi improvvisamente difettosi. Interi dischi possono smettere di funzionare inaspettatamente. I RAID proteggono da qualche settore che diviene difettoso o anche dal crash di un intero disco, ma non proteggono contro errori di scrittura di dati sbagliati e non proteggono nemmeno dai crash che avvengono in fase di scrittura e che corrompono i dati originali, senza sostituirli con nuovi dati. Per alcune applicazioni è fondamentale che i dati non siano mai persi o corrotti, anche a fronte di errori di disco o di CPU. L’ideale sarebbe un disco che lavorasse tutto il tempo senza errori. Sfortunatamente non si riesce a ottenere. Quello che si può avere è un sottosistema disco con la seguente proprietà: quando gli viene inviata un’operazione di scrittura, il disco o scrive correttamente i dati o non fa niente, lasciando i dati esistenti inalterati. Un sistema di questo genere è detto stable storage (memoria stabile) (Lampson e Sturgis, 1979). L’obiettivo è la consistenza del disco a ogni costo. A segui­re viene descritta una leggera variante all’idea ­originale.

Prima di descrivere l’algoritmo è importante avere un modello chiaro dei possibili errori. Il modello presuppone che quando un disco scrive un blocco (uno o più settori), l’operazione di scrittura è corretta o non lo è; questo errore può essere rilevato durante una lettura successiva esaminando i valori dei campi ECC. In linea di principio, non è mai possibile garantire la rilevazione dell’errore poiché, per esempio, con un campo ECC a 16 byte a guardia di un settore di 512 byte, ci sono 24096 valori di dati e solo 2144 valori di ECC. Così, se un blocco è confuso durante l’operazione di scrittura, ma l’ECC non lo è, ci sono miliardi e miliardi di combinazioni sbagliate, ma con lo stesso ECC. Se ne capita una di queste, l’errore non è rilevato. Nel complesso, la probabilità di avere dati presi a caso con l’ECC da 16 byte valido è circa 2–144, un valore abbastanza basso da essere considerato zero, sebbene non lo sia realmente.

Il modello presuppone anche che un settore scritto correttamente possa divenire spontaneamente difettoso e illeggibile. Tuttavia l’assunto è che questo genere di eventi sia così raro che la possibilità che si verifichi lo stesso problema al medesimo settore, su di un disco (indipendente) nel volgere di un intervallo ragionevole (per esempio 1 giorno) è praticamente zero.

Il modello considera anche che la CPU possa guastarsi e in questo caso semplicemente si ferma. Anche qualunque operazione di scrittura del disco in corso al momento del crash si ferma, con il risultato di un settore con dati non corretti e di un ECC non corretto che potrà essere rilevato in seguito. Sottostando a tutte queste condizioni, si può rendere la memoria stabile affidabile al 100%, nel senso di operazioni di scrittura che funzionano correttamente o che lasciano i vecchi dati al loro posto. Non protegge ovviamente da disastri fisici, come un terremoto e conseguente caduta di 100 metri del computer in una voragine con atterraggio in una vasca di magma bollente. È dura eseguire un ripristino via software a partire da queste condizioni.

La memoria stabile utilizza una coppia di dischi identici con i blocchi corrispondenti che lavorano insieme a formare un blocco esente da errori. In assenza di errori i blocchi corrispondenti di entrambi i dischi sono identici. Qualunque dei due sia letto, il risultato è lo stesso.

Per ottenere questo risultato sono definite le tre operazioni seguenti.

-   Operazioni di scrittura stabili. 

    -   Un’operazione di scrittura stabile consiste nello scrivere prima il blocco sull’unità 1, quindi leggerlo per verificare che sia stato scritto correttamente. Se non è stato scritto correttamente allora l’operazione di scrittura e la lettura sono rifatte per n volte finché non funzionano. Dopo n tentativi falliti il blocco è rimappato con uno di riserva e l’operazione ripetuta finché non funziona, non importa quanti blocchi di riserva debbano essere utilizzati. Non appena l’operazione di scrittura sul disco 1 è andata a buon fine, il blocco corrispondente viene scritto sul disco 2 e quindi riletto, ripetutamente se necessario, finché anch’esso non funziona. In assenza di crash della CPU, quando un’operazione di scrittura stabile viene completata, il blocco è stato scritto correttamente e verificato su entrambi i dischi.

-   Operazioni di lettura stabili. 
    
    -   Un’operazione di lettura stabile legge per primo un blocco dal disco 1. Se questo porta a un ECC scorretto, l’operazione di lettura si ritenta di nuovo, per n volte. Se risulta ancora un ECC sbagliato, viene letto il blocco corrispondente dal disco 2. Dato che un’operazione di scrittura stabile positiva lascia alle spalle due coppie valide di blocchi e dato che riteniamo trascurabile la probabilità che si guasti spontaneamente lo stesso blocco di entrambi i dischi in un intervallo di tempo ragionevole, un’operazione di lettura stabile ha sempre successo.

-   Crash recovery (ripristino da un crash). 

    -   Dopo un crash, un programma di ripristino fa la scansione di entrambi i dischi per fare il confronto dei blocchi corrispondenti. Se una coppia di blocchi è valida e sono identici, non viene fatto nulla. Se uno di loro presenta un errore di ECC, il blocco difettoso è sovrascritto con quello valido. Se sono entrambi senza errori ma diversi fra loro, il blocco sul disco 1 sovrascrive il blocco del disco 2.

In assenza di crash della CPU questo schema funziona sempre, dato che la memoria stabile scrive sempre due copie valide di ciascun blocco e che si presuppone che non avvengano errori spontanei su due blocchi corrispondenti e nel medesimo istante. Che cosa fare nel caso di crash della CPU durante operazioni di scrittura stabili? Dipende da dove avviene esattamente il crash. Le possibilità sono cinque, come descritto nella Figura 5.27.



Analisi dell’influenza dei crash sulle operazioni di scrittura stabili.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-31.png)

Nella Figura 5.27(a) il crash della CPU avviene prima della scrittura di entrambe le copie. Durante il ripristino non viene cambiato nulla e i vecchi dati persistono, il che è consentito.

Nella Figura 5.27(b) la CPU va in errore durante la scrittura sul disco 1, distruggendo i contenuti del blocco. Tuttavia il programma di ripristino rileva questo errore e recupera il vecchio blocco del disco 1 dal disco 2. L’effetto del crash è cancellato e la vecchia situazione del tutto recuperata.

Nella Figura 5.27(c) il crash avviene dopo la scrittura sul disco 1 ma prima della scrittura sul disco 2. In questo caso è stato superato il punto di non ritorno e il disco 1 è copiato sul disco 2. L’operazione di scrittura ha successo.

La Figura 5.27(d) è analoga alla Figura 5.27(b): durante il ripristino, il blocco buono sovrascrive il blocco guasto. Anche in questo caso il valore finale dei blocchi è quello nuovo.

Infine, nella Figura 5.27(e) il programma di ripristino vede che entrambi i blocchi sono identici, così non modifica nulla e anche in questo caso l’operazione di scrittura ha successo.

Sono possibili diverse ottimizzazioni e miglioramenti di questo modello. Innanzitutto, il confronto di tutti i blocchi, a coppie, dopo un crash è fattibile ma costoso. Un miglioramento considerevole è tener traccia del blocco che viene scritto durante un’operazione di scrittura stabile, per far sì che sia l’unico blocco da controllare durante un ripristino. Alcuni computer hanno una piccola quantità di memoria RAM non volatile, che è una memoria CMOS speciale alimentata da una batteria al litio. Queste batterie durano anni, anche l’intera vita del computer. Diversamente dalla memoria principale, che viene persa con un crash, questo non accade alla memoria RAM non volatile. L’ora del giorno è normalmente conservata in questa batteria (e incrementata da un circuito speciale) ed è per questo che i computer conoscono l’ora anche se la spina è stata staccata.

Supponete che qualche byte di memoria RAM non volatile sia disponibile per il sistema operativo. Prima di cominciare l’operazione di scrittura, l’operazione di scrittura stabile potrebbe mettere il numero del blocco che sta per aggiornare nella memoria RAM non volatile. Dopo aver completato con successo l’operazione di scrittura stabile, il numero di blocco della RAM non volatile potrebbe essere sostituito con un numero di blocco non valido, per esempio –1. A queste condizioni, dopo un crash, il programma di ripristino potrebbe controllare la RAM non volatile per vedere se era in corso l’operazione di scrittura stabile durante il crash e, in questo caso, quale blocco era in scrittura quando è occorso il crash. Per correttezza e consistenza potrebbero essere verificate due copie del blocco.

Se la RAM non volatile non è disponibile, la si può simulare nel modo seguente. Alla partenza dell’operazione di scrittura stabile, un blocco del disco prefissato sul disco 1 è sovrascritto con il numero del blocco dell’operazione di scrittura stabile. Questo blocco è anche riletto, ai fini di verifica, dopodiché è scritto e verificato anche il blocco sul disco 2. Terminata positivamente l’operazione di scrittura stabile, entrambi i blocchi sono scritti e verificati con un numero di blocco non valido. Anche qui, in caso di crash, è facile determinare se al momento del crash fosse in corso o meno un’operazione di scrittura stabile. Naturalmente questa tecnica richiede otto operazioni aggiuntive all’operazione di scrittura stabile, quindi andrebbe usata con estrema parsimonia.

Vale la pena puntualizzare un’ultima cosa. Abbiamo dato per scontato che possa passare dallo stato di blocchi validi allo stato di blocchi difettosi solo una coppia di blocchi al giorno. Per questo motivo una scansione completa dei dischi deve essere fatta una volta al giorno, per riparare qualsiasi danno. Facendo così ogni mattina i due dischi risulterebbero identici. Anche se entrambi i blocchi di una coppia divenissero difettosi nel giro di qualche giorno, tutti gli errori sarebbero riparati correttamente.