# 8.3 Sistemi Distribuiti

>**DEF:** Un Sistema Distribuito è una collezione di computer indipendenti che appaiono agli utenti come un sistema singolo e coerente.

Questi sistemi sono simili ai multicomputer, nel senso che ogni nodo ha la sua memoria privata, senza memoria fisica condivisa nel sistema. Tuttavia, i sistemi distribuiti sono ancora più debolmente strutturati dei multicomputer.


Inoltre, tutti i nodi di un multicomputer eseguono lo stesso sistema operativo e condividono un unico file system, mentre i nodi di un sistema distribuito possono ciascuno funzionare con un diverso sistema operativo e ognuno dei quali ha il suo personale file system.


### **`Esempio di Sistema Distribuito`**

![alt text](https://i.imgur.com/UdRwbMr.png)

Vari esempi di Sistemi Distribuiti: `Un Cluster`, `Rete Peer-to-Peer`, `Sistema di prenotazioni voli`, `Il World Wide Wibe`.

Inoltre i Sistemi Distributivi hanno degli obiettivi da tenere in considerazione:

-   Connettere vari utenti e varie risorse 

-   Offrire trasparenza

-   Essere disponibile attraverso la rete

-   Essere scalabile

-   Grande tolleranza dei guasti

&nbsp;
&nbsp;
&nbsp;

Per quanto la trasparenza, ci sono vari campi che la definiscono:


| **Tipo di Trasparenza** 	| **Descrizione**                                                                            	|
|-------------------------	|--------------------------------------------------------------------------------------------	|
| Accesso                 	| Nasconde le differenze nella rappresentazione dei dati e su come la risorsa è acceduta.    	|
| Locazione               	| Nasconde dove una risorsa si trova.                                                        	|
| Migrazione              	| Nasconde che una risorsa si possa spostare in una differente locazione.                    	|
| Rilocazione             	| Nasconde che una risorsa si possa spostare in una differente locazione mentre viene usata. 	|
| Replicazione            	| Nasconde che una risorsa possa essere replicata.                                           	|
| Concurrenza             	| Nasconde che una risorsa posso essere condivisa da più utenti concorrenti.                 	|
| Fallimenti              	| Nasconde che il guasto e il recovery di una risorsa.                                       	|
| Persistenza             	| Nasconde che una risorsa (anche software) è in memoria o nel disco.                        	|



Se utilizziamo queste metriche, i multicomputer sono chiaramente nel mezzo. Una domanda interessante è: “I multicomputer sono più simili ai multiprocessori o ai sistemi distribuiti?” La risposta dipende fortemente dalle vostre prospettive. Da un punto di vista tecnico, i multiprocessori hanno una memoria condivisa e gli altri due no. Questa differenza genera diversi modelli di programmazione e un atteggiamento mentale differente. Tuttavia, per quanto riguarda la prospettiva delle applicazioni, i multiprocessori e i multicomputer sono solo grandi scaffalature di attrezzature in una sala macchine. Entrambi sono utilizzati per risolvere problemi intensivi dal punto di vista elaborativo, mentre un sistema distribuito che collega computer su Internet è in genere maggiormente coinvolto in comunicazioni più che elaborazioni e si utilizza in modo diverso.

Per certi versi, la debole struttura dei computer in un sistema distribuito è sia un punto di forza che di debolezza. È un punto di forza perché i computer sono utilizzabili per una grande varietà di applicazioni, ma è anche un punto di debolezza, perché la programmazione di tali applicazioni è difficoltosa per la mancanza di un modello sottostante comune.

Le applicazioni tipiche di Internet comprendono l’accesso a computer remoti (utilizzando telnet, ssh e rlogin ), l’accesso a informazioni remote (utilizzando il World Wide Web e l’FTP, il File Transfer Protocol), la comunicazione persona-a-persona (utilizzando programmi di e-mail e chat) e molte altre applicazioni emergenti (come il commercio elettronico, la telemedicina e i corsi on-line a distanza). Il problema di tutte queste applicazioni è che ognuna deve ricominciare da capo. Per esempio, e-mail, FTP e World Wide Web fondamentalmente spostano file da un punto A a un punto B, ma ognuno ha il suo modo di farlo, completo delle sue regole di naming, protocolli di trasferimento, tecniche di replica e tutto il resto. Sebbene molti browser web nascondano queste differenze all’utente medio, i meccanismi basilari sono completamente differenti. Nasconderli a livello d’interfaccia utente è come ordinare un viaggio da New York a San Francisco presso un sito web full-service di un’agenzia di viaggi e scoprire solo alla fine se si è acquistato un biglietto aereo, ferroviario o per un autobus.

Quello che i sistemi distribuiti aggiungono alla rete sottostante è un paradigma comune (modello) che fornisce un modo uniforme di guardare all’intero sistema. Lo scopo dei sistemi distribuiti è quello di trasformare un gruppo di macchine connesse debolmente in un sistema coerente basato su un unico concetto. A volte il paradigma è semplice e a volte è più elaborato, ma l’idea è sempre quella di fornire qualcosa che unifichi il sistema.

Un esempio semplice di paradigma unificante in un contesto leggermente diverso si ritrova in UNIX, dove tutti i dispositivi di I/O vengono fatti assomigliare a dei file. Disporre di tastiere, stampanti e linee seriali che operano tutte nello stesso modo, con le stesse primitive, ne semplifica l’impiego rispetto all’averle tutte concettualmente differenti.

Un modo in cui un sistema distribuito può raggiungere una certa misura di uniformità a fronte di hardware e sistemi operativi sottostanti differenti è avere un livello di software al di sopra del sistema operativo. Questo livello, chiamato middleware, è illustrato nella Figura 8.27 e fornisce determinate strutture di dati e operazioni che permettono ai processi e agli utenti di macchine remote di interagire in modo consistente.





Posizionamento del middleware in un sistema distribuito.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-30.png)

In un certo senso, il middleware è come il sistema operativo di un sistema distribuito; per questo motivo si tratta questo argomento in un libro sui sistemi operativi. Di contro, non è realmente un sistema operativo, per cui l’analisi non entrerà troppo nel dettaglio. Per un maggiore approfondimento fate riferimento al volume Sistemi distribuiti (traduzione italiana, Tanenbaum e Van Steen, 2006).

Nel resto del capitolo analizzeremo velocemente l’hardware utilizzato in un sistema distribuito (cioè la rete di computer sottostante), poi il suo software di comunicazione (i protocolli di rete). In seguito considereremo una gamma di paradigmi utilizzati in questi sistemi.

&nbsp;
&nbsp;
&nbsp;

*Hardware di Rete*
====

I sistemi distribuiti sono costruiti al di sopra delle reti di computer, per cui una breve introduzione a questo argomento è d’obbligo. Esistono due importanti tipologie di reti, le LAN (local area networks), che servono un edificio o un campus e le WAN (wide area networks), che possono essere estese quanto una città, uno stato o anche su scala mondiale. Il tipo più importante di LAN è Ethernet, quindi la esamineremo come esempio di LAN. Come esempio di WAN esamineremo Internet, anche se dal punto di vista tecnico Internet non è una rete unica ma una federazione di migliaia di reti separate. Tuttavia, per i nostri scopi, è sufficiente pensare a essa come a una WAN.

&nbsp;
&nbsp;
&nbsp;

    Ethernet

La classica Ethernet, descritta nello Standard IEEE 802.3, consiste di un cavo coassiale al quale sono collegati un certo numero di computer. Il cavo è chiamato Ethernet, in riferimento all’etere luminifero (luminiferous ether) attraverso il quale un tempo si pensava si propagassero le onde elettromagnetiche. (Quando il fisico inglese del XIX secolo James Clerk Maxwell scoprì che le onde elettromagnetiche potevano essere descritte da un’equazione d’onda, gli scienziati ritennero che lo spazio dovesse essere riempito con una qualche sostanza eterea nella quale le radiazioni potessero propagarsi. Solo nel 1887 dopo il famoso esperimento MichelsonMorley, che fallì nell’identificare l’etere, i fisici realizzarono che le radiazioni potevano propagarsi nel vuoto.)

Nella primissima versione di Ethernet, un computer era collegato al cavo attraverso un buco in mezzo al cavo stesso e avvitandovi un filo che portava al computer. Fu chiamato vampire tap, schematicamente mostrato nella Figura 8.28(a). Dato che era difficile far funzionare correttamente i tap, essi furono sostituiti da connettori appropriati. Tuttavia, dal punto di vista elettrico, tutti i computer erano connessi come se i cavi sulle loro schede d’interfaccia di rete fossero saldati insieme.



(a) Ethernet classica. (b) Ethernet con switch.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-31.png)

Per spedire un pacchetto su una Ethernet, un computer verifica prima sul cavo per vedere se altri computer stanno trasmettendo in quel momento. Altrimenti, inizia semplicemente a trasmettere un pacchetto, che consiste di una breve intestazione seguita da un carico utile da 0 a 1500 byte. Se il cavo è in uso, il computer attende la fine della trasmissione in atto, poi inizia il suo invio.

Se due computer iniziano a trasmettere simultaneamente, ne risulta una collisione rilevata da entrambi. Entrambi rispondono terminando le loro trasmissioni, aspettando un tempo casuale tra 0 e T µs e poi ricominciando di nuovo. Se si verifica un’altra collisione, tutti i computer che si scontrano randomizzano l’attesa nell’intervallo da 0 a 2T µs e poi provano nuovamente. Per ogni ulteriore collisione, l’intervallo massimo di attesa è raddoppiato, riducendo la possibilità di altre collisioni. Questo algoritmo è conosciuto come binary exponential backoff, visto precedentemente per ridurre l’overhead del polling sui lock.

Una Ethernet ha una lunghezza massima del cavo e un numero massimo di computer che si possono collegare. Per superare ciascuno di questi limiti, grandi edifici o campus possono essere cablati con più Ethernet, a loro volta collegate da dispositivi chiamati bridge. Un bridge permette che il traffico passi da una Ethernet all’altra, quando la sorgente è da un lato e il destinatario dall’altro. Per evitare il problema delle collisioni, le Ethernet moderne utilizzano degli switch, come mostrato nella Figura 8.28(b). Ogni switch ha un certo numero di porte, alle quali possono essere connessi un computer, una Ethernet o un altro switch. Quando un pacchetto evita con successo tutte le collisioni e raggiunge lo switch, è messo nel buffer ed è inviato sulla porta dove si trova la macchina di destinazione. Dotando ogni computer della sua porta esclusiva, possono essere eliminate tutte le collisioni, a costo di switch più grandi. Sono anche possibili dei compromessi, con solo pochi computer per porta. Nella Figura 8.28(b) una Ethernet classica con più computer collegati a un cavo da un vampire tap è a sua volta connessa a una delle porte dello switch.

&nbsp;
&nbsp;
&nbsp;

    Internet

Internet si è evoluta a partire da ARPANET, una rete sperimentale a commutazione di pacchetto fondata dall’Agenzia dei Progetti di Ricerca Avanzata del Dipartimento della Difesa degli Stati Uniti. Entrò in funzione nel dicembre 1969 con tre computer in California e uno nello Utah. Fu progettata all’apice della guerra fredda per essere una rete tollerante ai malfunzionamenti, in grado di continuare a trasmettere traffico militare anche nell’eventualità di attacchi nucleari diretti a più punti della rete, tramite l’automatico reinstradamento del traffico attorno alle macchine fuori uso.

ARPANET crebbe rapidamente negli anni ’70, comprendendo alla fine centinaia di computer. In seguito furono collegate a essa una rete radio a pacchetti, una rete satellitare e infine migliaia di Ethernet, dando vita alla federazione di reti che ora conosciamo come Internet.

Internet è composta di due tipi di computer, host e router. Gli host sono PC, notebook, palmari, server, mainframe e altri computer di proprietà di individui o di aziende che si vogliono connettere a Internet. I router sono computer specializzati nella commutazione (switching) che accettano pacchetti in arrivo su una di tante linee in entrata e li inviano alle loro destinazioni lungo una delle tante vie in uscita. Un router è simile allo switch della Figura 8.28(b), ma si differenzia per caratteristiche che al momento non ci interessano. I router sono collegati fra di loro a formare reti vaste, in cui ogni router ha cavi o fibre verso molti altri router e host. Le grandi reti di router nazionali o mondiali sono gestite da compagnie telefoniche e ISP (Internet service providers) per i loro clienti.

La Figura 8.29 mostra una sezione di Internet. In alto troviamo una delle linee dorsali (backbone), gestite normalmente da un operatore di dorsali. Consiste di un certo numero di router collegati con fibre ottiche a elevata ampiezza di banda, con connessioni verso le dorsali effettuate da altre compagnie telefoniche (concorrenti). Di solito, nessun host è connesso direttamente alla dorsale, eccetto macchine test o di manutenzione della compagnia telefonica.



Sezione di Internet

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-32.png)


Collegate ai router delle dorsali ci sono le reti di zona e i router degli ISP, tramite connessioni di fibre ottiche di media velocità. A loro volta, le Ethernet aziendali hanno ognuna un router, questi router sono collegati ai router delle reti di zona. I router degli ISP sono collegati ai banchi dei modem usati dai clienti degli ISP. In questo modo, ogni host in Internet ha almeno un percorso, e spesso più percorsi, verso ogni altro host.

Tutto il traffico in Internet è inviato sotto forma di pacchetti. Ogni pacchetto porta al suo interno il proprio indirizzo di destinazione: questo indirizzo è utilizzato per l’instradamento. Quando un pacchetto arriva in un router, esso estrae l’indirizzo di destinazione e lo verifica (per una parte) in una tabella per trovare su quale linea in uscita deve inviare il pacchetto, cioè a quale router. Questa procedura è ripetuta finché il pacchetto non raggiunge l’host di destinazione. Le tabelle d’instradamento sono estremamente dinamiche e continuamente aggiornate della caduta o della riattivazione dei router, dei collegamenti e di qualsiasi cambiamento delle condizioni del traffico.

&nbsp;
&nbsp;
&nbsp;

*Protocolli e Servizi di Rete*
====

Le reti di computer forniscono ai loro utenti (host e processi) determinati servizi, che implementano utilizzando regole stabilite sullo scambio di messaggi legali. Di seguito forniremo una breve introduzione a questi argomenti.

&nbsp;
&nbsp;
&nbsp;

    Servizi di Rete

Le reti di computer forniscono servizi agli host e ai processi che le utilizzano. Il modello del servizio orientato alla connessione (connection-oriented) è basato sul sistema telefonico. Per comunicare con qualcuno, si prende il telefono, si digita il numero, si parla e poi si aggancia. Analogamente, per utilizzare un servizio di rete orientato alla connessione, l’utente del servizio stabilisce prima una connessione, la usa e poi la rilascia. L’aspetto essenziale della connessione è che essa agisce come un tubo: il mittente spinge dentro gli oggetti (i bit) a una estremità e il destinatario li riceve nello stesso ordine all’estremità opposta.

Diversamente, il modello del servizio senza connessione (connectionless ) ha come modello il sistema postale. Ogni messaggio (lettera) porta l’indirizzo di destinazione completo e ogni messaggio è convogliato attraverso il sistema indipendentemente da tutti gli altri. Di norma, quando due messaggi sono spediti alla stessa destinazione, quello spedito per primo sarà il primo ad arrivare. Tuttavia, è possibile che quello spedito per primo possa subire un ritardo, cosicché arrivi prima il secondo. Con un servizio orientato alla connessione questo sarebbe impossibile.

Ogni servizio si può classificare in base alla qualità del servizio. Alcuni sono affidabili, nel senso che non perdono mai dati. Solitamente, un servizio affidabile è implementato con il destinatario che conferma la ricezione di ciascun messaggio rispedendo uno speciale pacchetto di conferma di ricezione (acknowledgement packet ), in modo che il mittente abbia la certezza che il messaggio è arrivato. Il processo di conferma di ricezione provoca costi e ritardi, necessari per individuare la perdita di pacchetti, ma che rallentano il tutto.

Il trasferimento di file è una tipica situazione in cui è appropriato un servizio orientato alla connessione affidabile. Il proprietario del file vuole essere certo che tutti i bit arrivino correttamente e nello stesso ordine di spedizione. Solo pochi utenti preferirebbero un servizio di trasferimento di file più veloce che occasionalmente mescolasse o perdesse anche pochi bit.

Il servizio affidabile orientato alla connessione ha due varianti secondarie: sequenze di messaggi (message sequence ) e flussi di byte (byte stream ). Nella prima, sono preservati i confini dei messaggi. Quando sono spediti due messaggi da 1 KB, essi arrivano come due distinti messaggi da 1 KB e mai come un messaggio da 2 KB. Nella seconda variante, la connessione è semplicemente un flusso (stream) di byte, senza divisione tra i messaggi. Quando arrivano al destinatario 2 KB, non c’è modo di indicare se siano stati spediti come un messaggio da 2 KB, due messaggi da 1 KB o 2048 messaggi da 1 byte. Se le pagine di un libro fossero spedite sulla rete a un impianto di stampa come messaggi separati, mantenere i confini dei messaggi potrebbe essere importante. D’altra parte, nel caso di un terminale che si collega a un sistema remoto in time sharing, basterebbe un flusso di byte dal terminale al computer.

Per alcune applicazioni il ritardo generato dalla conferma di ricezione è inaccettabile. Un’applicazione di questo genere è il traffico vocale digitalizzato. Gli utenti telefonici preferiscono sentire un po’ di rumore sulla linea o una voce confusa ogni tanto piuttosto che un ritardo dovuto alla conferma di ricezione.

Non tutte le applicazioni richiedono connessioni. Per esempio, per testare la rete tutto ciò che serve è un modo per spedire un singolo pacchetto che abbia una elevata probabilità di arrivo, senza alcuna garanzia. Un servizio senza connessione non affidabile (cioè privo di conferma di ricezione) è spesso chiamato servizio datagram, per analogia con il servizio dei telegrammi, che allo stesso modo non fornisce una conferma di ricezione al mittente.

In altre situazioni, la convenienza di non dover stabilire una connessione per spedire un breve messaggio è auspicabile, ma l’affidabilità è essenziale. Per queste applicazioni si può fornire il servizio datagram con conferma (acknowledged datagram service ). È come spedire una lettera raccomandata con ricevuta di ritorno. Quando ritorna la ricevuta, il mittente è assolutamente certo che la lettera sia stata consegnata al destinatario e che non sia stata smarrita lungo il percorso.

Un altro servizio è quello del servizio richiesta-risposta (request-reply service). In questo servizio il mittente trasmette un singolo datagram contenente una richiesta; la replica contiene la risposta. Il servizio richiesta-risposta è comunemente utilizzato per implementare le comunicazioni nel modello client-server: il client invia una richiesta e il server gli risponde. La Figura 8.30 riassume i tipi di servizio di cui si è appena discusso.



Sei differenti tipologie di servizio rete.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-33.png)

&nbsp;
&nbsp;
&nbsp;

    Protocolli di Rete

Tutte le reti hanno regole altamente specialistiche relative a quali messaggi possono essere spediti e a quali repliche possono essere restituite in risposta a questi messaggi. Per esempio, in certe circostanze (per esempio, il trasferimento di file), quando un messaggio è spedito da una sorgente a una destinazione, si richiede alla destinazione di spedire una conferma di ricevuta indicante la corretta ricezione del messaggio. In altre circostanze (per esempio, nella telefonia digitale), non ci si aspetta questa conferma di ricezione. L’insieme di regole tramite le quali comunicano particolari computer è detto protocollo. Esistono molti protocolli, inclusi protocolli router-router, protocolli host-host e altri. Per un’analisi approfondita delle reti di computer e dei loro protocolli, si faccia riferimento a Reti di computer (traduzione italiana, Tanenbaum, 2003).

Per stratificare protocolli diversi uno sopra all’altro tutte le reti moderne utilizzano quella che si definisce pila di protocolli (protocol stack). A ogni strato vengono trattate questioni diverse. Per esempio, al livello più basso i protocolli definiscono come indicare l’inizio e la fine di un pacchetto nel flusso dei bit. A un livello superiore i protocolli trattano di come instradare i pacchetti dalla sorgente alla destinazione attraverso reti complesse. A un livello ancora più alto, essi si assicurano che tutti i pacchetti, in un messaggio multipacchetto, siano arrivati correttamente e nell’ordine corretto.

Dal momento che molti sistemi distribuiti utilizzano Internet come base, i protocolli chiave sfruttati da questi sistemi sono i due principali protocolli di Internet: IP e TCP. IP (Internet protocol) è un protocollo datagram nel quale un mittente inserisce un datagram di circa 64 KB sulla rete, auspicando che esso arrivi. Non gli è data alcuna garanzia. Mentre passa attraverso Internet il datagram può essere frammentato in pacchetti più piccoli, che viaggiano in maniera indipendente, forse lungo percorsi diversi. Raggiunta la loro destinazione, tutti i pezzi sono assemblati nell’ordine corretto e consegnati.

Attualmente sono in uso due versioni di IP, la v4 e la v6. Al momento la v4 ha ancora il sopravvento, per cui qui descriveremo quella, ma la v6 sta avanzando. Ogni pacchetto v4 comincia con un’intestazione di 40 byte e contiene fra gli altri campi un indirizzo sorgente di 32 bit e un indirizzo destinazione di 32 bit. Questi sono denominati indirizzi IP e formano le basi dell’instradamento in Internet. Sono convenzionalmente scritti come quattro numeri decimali che vanno da 0 a 255, separati dai punti, come 192.31.231.65. Quando giunge un pacchetto al router, questo estrae l’indirizzo IP di destinazione e lo usa per l’instradamento del pacchetto.

Dato che i datagram IP non comportano conferma, l’IP da solo non è sufficiente per ottenere comunicazioni affidabili su Internet. Per fornire comunicazioni affidabili solitamente si stratifica un altro protocollo al di sopra dell’IP, il TCP (transmission control protocol). Il TCP utilizza l’IP per fornire flussi orientati alla connessione. Per usare il TCP, un processo prima stabilisce una connessione a un processo remoto. Il processo richiesto è specificato dall’indirizzo IP di una macchina e da un numero di porta di quella macchina, su cui stanno in ascolto i processi interessati alla ricezione di connessioni in ingresso. A connessione avvenuta, semplicemente pompa byte lungo di essa con la garanzia che essi arrivino dall’altro capo integri e nell’ordine corretto. L’implementazione del TCP ottiene questa garanzia usando numeri di sequenza, somme di controllo (checksums) e la ritrasmissione dei pacchetti ricevuti in modo scorretto. Tutto ciò è trasparente ai processi di trasmissione e di ricezione. Tutto quello che vedono è una comunicazione fra processi affidabile, proprio come una pipe UNIX.

Per vedere come interagiscono tutti questi protocolli considerate il caso di un piccolissimo messaggio che non debba essere frammentato, ad alcun livello. L’host è su una Ethernet connessa a Internet. Che cosa accade esattamente? Il processo utente genera il messaggio e fa una chiamata di sistema per inviarlo su una connessione TCP precedentemente stabilita.

La pila dei protocolli del kernel aggiunge un’intestazione TCP e poi un’intestazione IP davanti al messaggio. Poi va al driver Ethernet, che aggiunge un’intestazione Ethernet che direziona il pacchetto al router sulla Ethernet. Questo router a sua volta inserisce il pacchetto su Internet, come descritto nella Figura 8.31.



Accomulazione di intestazioni dei pacchetti

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-34.png)

Per stabilire una connessione con un host remoto (o anche per spedirgli un datagram), serve conoscere il suo indirizzo IP. Poiché gestire elenchi di indirizzi IP a 32 bit è scomodo per gli utenti, fu inventato uno schema chiamato DNS (domain name system – sistema di denominazione dei domìni), una base di dati che mappi i nomi ASCII degli host ai loro indirizzi IP. In questo modo è possibile usare il nome DNS star.cs.vu.nl invece del suo corrispondente indirizzo IP 130.37.24.6. I nomi DNS sono largamente conosciuti, dato che gli indirizzi Internet di posta elettronica sono nel formato nome-utente@nome-host-DNS. Questo sistema di nomenclatura consente al programma di posta elettronica sull’host mittente di cercare l’indirizzo IP dell’host di destinazione, stabilire una connessione TCP con il processo demone della posta elettronica e spedire il messaggio come un file. Il nome-utente è spedito per identificare in quale casella postale posizionare il messaggio.

&nbsp;
&nbsp;
&nbsp;

*Middleware basato sui documenti*
====

Adesso che abbiamo acquisito alcune cognizioni sulle reti e sui protocolli possiamo cominciare ad analizzare i diversi livelli di middleware che possono posizionarsi sulla rete base per produrre un paradigma coerente per le applicazioni e gli utenti. Partiremo da un esempio semplice ma ben conosciuto: il World Wide Web. Il Web fu inventato nel 1989 da Tim BernersLee al CERN, il centro europeo per la ricerca fisico-nucleare e si è allargato nel mondo a macchia d’olio.

Il paradigma originale che sta alla base del Web è abbastanza semplice: ogni computer può contenere uno o più documenti, chiamati pagine web. Ciascuna pagina web contiene testo, immagini, icone, suoni, filmati e cose simili, così come link ipertestuali o hyperlink (puntatori) ad altre pagine web. Quando, tramite un programma chiamato browser web, un utente richiede una pagina web, questa è visualizzata sullo schermo. Cliccando su un link la pagina attuale viene sostituita sullo schermo dalla pagina cui il link punta. Sebbene recentemente siano stati aggiunti al Web molti fronzoli, il paradigma sottostante rimane chiaramente valido: il Web è un immenso grande grafo orientato di documenti che puntano ad altri documenti, come mostrato nella Figura 8.32.




Il Web è un grande grafo orientato di documenti.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-35.png)

Ogni pagina web ha un indirizzo univoco, chiamato URL (uniform resource locator), nella forma protocollo://nome-DNS/nome-file. Nella maggior parte dei casi il protocollo è http (hypertext transfer protocol ), ma esistono anche ftp e altri. Quindi segue il nome DNS dell’host contenente il file. Alla fine vi è il nome locale del file che indica quale file si desidera.

Il modo in cui l’intero sistema sta insieme è il seguente. Il Web fondamentalmente è un sistema client-server, con l’utente che è il client e il sito web che è il server. Quando l’utente fornisce un URL al browser, sia digitando un indirizzo o cliccando su un link ipertestuale della pagina attuale, il browser mette in atto alcuni passaggi per prelevare la pagina web richiesta.

Come semplice esempio supponete che l’URL fornito sia http://minix3.org/doc/faq.html. Per ottenere la pagina il browser fa i seguenti passaggi:

-   Il browser chiede al DNS l’indirizzo IP di www.minix3.org.

-   Il DNS risponde con 130.37.20.20.

-   Il browser esegue una connessione TCP alla porta 80 su 130.37.20.20.

-   A seguire invia una richiesta per il file doc/faq.html.

-   Il server invia il file doc/faq.html.

-   La connessione TCP è rilasciata.   

-   Il browser visualizza tutto il testo contenuto in doc/faq.html.

Approssimativamente questa è la base del Web e del suo funzionamento. A oggi sono state aggiunte molte altre caratteristiche, come gli stili, le pagine web dinamiche generate al momento, le pagine web contenenti piccoli programmi o script che si eseguono sulla macchina del client e altro, argomenti però al di là dello scopo di questo libro.

&nbsp;
&nbsp;
&nbsp;

*Middleware basato su File System*
====

L’idea alla base del Web è rendere un sistema distribuito simile a una gigantesca raccolta di documenti collegati tramite link ipertestuali. Un secondo approccio è considerarlo come un grandissimo file system. In questo paragrafo analizzeremo alcune delle questioni riguardanti la progettazione di un file system su scala mondiale.

Usare un modello a file system per un sistema distribuito significa che vi è un solo file system globale, con utenti sparsi nel mondo in grado di leggere e scrivere i file cui sono autorizzati. La comunicazione è ottenuta tramite un processo che scrive dati in un file e gli altri che li leggono. Anche in questo caso sono presenti molti dei problemi relativi ai file system standard, ma ne sorgono anche altri relativi alla distribuzione.

&nbsp;
&nbsp;
&nbsp;

    Modello di Trasferimento

Il primo problema è la scelta fra il modello upload/download e il modello ad accesso remoto. Nel primo, mostrato nella Figura 8.33(a), un processo accede a un file per prima cosa copiandolo dal file server dove risiede. Se il file deve solo essere letto, la lettura è fatta localmente, per avere alte prestazioni. Se dev’essere scritto, è scritto localmente. Quando il processo ha terminato la scrittura, il file aggiornato è inviato al server. Con il modello ad accesso remoto, il file rimane sul server e i client inviano i comandi per fare il lavoro sul server, come illustrato nella Figura 8.33(b).



(a) Il modello upload/download. (b) Il modello ad accesso remoto.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-36.png)

I vantaggi del modello upload/download stanno nella sua semplicità e nel fatto che trasferire interi file in un sol colpo è più comodo che trasferirli a piccoli pezzi. Gli svantaggi consistono nella necessità di spazio sufficiente in locale per l’intero file, nel fatto che lo spostamento di un file intero è uno spreco qualora ne servano solo delle piccole parti e nella possibilità che sorgano dei problemi di consistenza nel caso di molteplici utenti concorrenti.

&nbsp;
&nbsp;
&nbsp;

    Gerarchia della directory

I file sono solo una parte della storia. L’altra parte è il sistema delle directory. Tutti i file system distribuiti supportano directory che contengono molteplici file. Il successivo problema progettuale è se tutti i client abbiano la medesima vista della gerarchia della directory. Come esempio da prendere in esame considerate la Figura 8.34. Nella Figura 8.34(a) abbiamo due file server, ognuno contenente tre directory e alcuni file. Nella Figura 8.34(b) abbiamo un sistema in cui tutti i client (e altre macchine) hanno la stessa vista del file system distribuito. Se il percorso /D/E/x è valido su di una macchina, lo è anche su tutte le altre.



(a) Due file server. I quadrati sono le directory e i cerchiolini sono i file. (b) Un sistema nel quale i client hanno la stessa vista del file system. (c) Un sistema nel quale i client possono avere viste differenti del file system.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-37.png)


Diversamente nella Figura 8.34(c), macchine diverse hanno viste diverse del file system. Per ripetere l’esempio precedente, il percorso /D/E/x potrebbe essere valido sul client 1 ma non sul client 2. In sistemi che gestiscono molteplici file server tramite il mounting (montaggio) remoto, la Figura 8.34(c) è la norma. È flessibile e semplice da implementare, ma ha lo svantaggio di non far sì che l’intero sistema si comporti come un solo sistema time sharing dei vecchi tempi. In un sistema time sharing il file system appare lo stesso a qual- siasi processo, come nel modello della Figura 8.34(b). Questa proprietà rende un sistema più semplice da programmare e da capire.

Una questione strettamente correlata è se vi sia o meno una root directory globale, che tutte le macchine riconoscano come root.

Un sistema per avere una root directory globale è che vi sia una root contenente una voce per ciascun server e nient’altro. A queste condizioni, i percorsi hanno una forma del tipo /server/path, con i suoi svantaggi, ma quanto meno con il vantaggio di essere lo stesso in tutto il sistema.

&nbsp;
&nbsp;
&nbsp;

    Trasparenza nel naming

Il problema principale di questo formato di nomenclatura è che non è completamente trasparente. In questo contesto sono importanti due forme di trasparenza che vale la pena distinguere. La prima, la trasparenza dalla posizione, significa che il percorso non dà adito a dubbi su dove si trovi il file. Un percorso del tipo /server1/dir1/dir2/x indica a tutti che x è posizionato sul server 1, ma non dice dove il server si trovi. Il server è libero di muoversi ovunque voglia nella rete senza che il nome del percorso debba essere modificato. Ciò significa che questo sistema ha la location transparency.

Supponete tuttavia che il file x sia estremamente grande e stia alla stretta sul server 1. Inoltre supponete che sul server 2 vi sia una gran quantità di spazio. Il sistema dovrebbe a ragion veduta muovere x sul server 2 in automatico. Sfortunatamente, quando il primo componente dei nomi del percorso è il server, il sistema non può spostare il file a un altro server automaticamente, anche se dir1 e dir2 esistono su entrambi i server. Il problema è che lo spostamento del file in automatico cambia il suo path name da /server1/dir1/dir2/x a /server2/dir1/dir2/x. I programmi che hanno la prima stringa inserita al loro interno smetteranno di funzionare se il percorso cambia. Un sistema in cui i file possono essere spostati senza che i loro nomi cambino è detto avere indipendenza alla posizione. Un sistema distribuito che incorpori nomi di macchine o di server nei path name è chiaramente non indipendente dal posizionamento. Nemmeno uno basato sul remote mounting lo è, dato che non è possibile spostare un file da un gruppo di file (l’unità del mounting ) a un altro ed essere ancora in grado di usare il vecchio path name. L’indipendenza dalla posizione non è semplice da ottenere, ma è una proprietà auspicabile in un sistema distribuito.

Per riassumere quanto detto finora, gli approcci comuni alla nomenclatura dei file e delle directory in un sistema distribuito sono tre.

-   Macchina + nome del percorso, come in /macchina/percorso o macchina:percorso.

-   Mounting di file system remoti sulla gerarchia dei file locali.

-   Uno spazio dei nomi singolo che appaia uguale su tutte le macchine.

I primi due approcci sono semplici da implementare, specialmente come modo di connettere dei file system esistenti non progettati per un uso distribuito. L’ultimo è difficile e richiede un’attenta progettazione, ma semplifica la vita a utenti e programmatori.

&nbsp;
&nbsp;
&nbsp;

    Semantica della condivisione dei file

Quando due o più utenti condividono lo stesso file per evitare problemi è necessario definire con precisione le semantiche di lettura e di scrittura. Nei sistemi a processore singolo le semantiche dichiarano che quando una chiamata di sistema read segue una chiamata di sistema write, la read restituisce il valore appena scritto, come mostrato nella Figura 8.35(a). In modo analogo, quando avvengono due write consecutive e poi una read, il valore letto è quello memorizzato dall’ultima scrittura. In effetti il sistema fa rispettare un ordine su tutte le chiamate di sistema e tutti i processori vedono lo stesso ordinamento. Faremo riferimento a questo modello con il nome di consistenza sequenziale.




(a) Consistenza sequenziale. (b) In un sistema distribuito che fa uso della cache, la lettura di un file può restituire un valore obsoleto.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-38.png)

In un sistema distribuito, la consistenza sequenziale può ottenersi facilmente purché vi sia un solo file server e i client non mettano i file nella cache. Tutte le read e le write vanno direttamente al file server, che le processa in modo strettamente sequenziale. In pratica, tuttavia, le prestazioni di un sistema distribuito in cui tutte le richieste dei file devono andare a un singolo server sono spesso scadenti. Questo problema è frequentemente risolto permettendo ai client di avere delle copie locali dei file usati più frequentemente nelle loro cache private. Tuttavia, se il client 1 modifica un file che ha nella cache locale e subito dopo il client 2 legge il file dal server, il secondo client prenderà un file obsoleto, come illustrato nella Figura 8.35(b).

Una soluzione per superare questo problema è la propagazione immediata al server di tutte le modifiche effettuate sui file nelle cache. Sebbene concettualmente semplice, questo metodo non è efficace. Un’alternativa è quella di rilassare la semantica della condivisione dei file. Invece di richiedere una read per vedere gli effetti di tutte le write precedenti, si potrebbe avere una nuova regola che afferma: “I cambiamenti a un file aperto sono inizialmente visibili solo al processo che li ha effettuati. Solo una volta che il file è stato chiuso i cambiamenti sono visibili agli altri processi”. Adottare una regola di questo genere non modifica quanto accade nella Figura 8.35(b), ma ridefinisce il comportamento reale (B che prende il valore originale del file) come quello corretto. Quando il client 1 chiude il file, restituisce una copia al server, in modo che le successive read prendano il nuovo valore, come richiesto. Questa regola semantica è diffusamente implementata ed è conosciuta come semantica di sessione.

L’uso della semantica di sessione porta al problema di che cosa accade quando due o più client mettono nella cache e modificano il medesimo file contemporaneamente. Una soluzione indica che ciascun file è chiuso a turno, il suo valore rispedito al server e che il risultato finale dipende da chi lo chiude per ultimo. Un’alternativa meno piacevole, ma più semplice da implementare, è che il risultato finale è uno dei due candidati, ma non specifica su quale dei due cada la scelta.

Un approccio alternativo alla semantica di sessione è l’uso del modello upload/download, ma ciò causa il lock immediato del file appena scaricato. I tentativi degli altri client di scaricare il file sarebbero posticipati a quando il primo client lo abbia restituito. Nel caso della massiccia richiesta di un file, il server potrebbe inviare dei messaggi al client che lo sta utilizzando, sollecitandogli di affrettarsi, ma non è detto che questo possa essere d’aiuto. In conclusione, far sì che la semantica della condivisione dei file funzioni bene è un problema non è semplice e non ci sono soluzioni eleganti ed efficienti.

&nbsp;
&nbsp;
&nbsp;

*Middleware basato su oggetti*
====

Prestiamo adesso attenzione a un terzo paradigma. Invece di dire che qualunque cosa è un documento o un file, diciamo che tutto è un oggetto. Un oggetto è una raccolta di variabili impacchettate con un insieme di procedure d’accesso, chiamate metodi. Ai processi non è consentito accedere direttamente alle variabili. Devono invece richiamare i metodi.

Alcuni linguaggi di programmazione, come C++ e Java, sono orientati agli oggetti (object-oriented), ma questi sono oggetti a livello di linguaggio, piuttosto che oggetti runtime. Un sistema ben conosciuto che si basa sugli oggetti run-time è CORBA (common object request broker architecture) (Vinoski, 1997). CORBA è un sistema client-server, in cui processi client su macchine client possono richiamare operazioni su oggetti posizionati su macchine server (eventualmente remote). CORBA fu progettato per un sistema eterogeneo eseguito su una varietà di piattaforme hardware e sistemi operativi e programmato in una varietà di linguaggi. Per rendere possibile che un client su una piattaforma richiami un server su una piattaforma differente sono interposti fra i client e i server degli ORB (object request broker), che ne permettono l’unione. Gli ORB hanno un ruolo importante in CORBA, come si capisce anche dal nome stesso dato al sistema.

Ogni oggetto CORBA è definito tramite una definizione d’interfaccia in un linguaggio chiamato IDL (interface definition language) che descrive quali metodi sono esportati dall’oggetto e che tipi di parametri ognuno si aspetti. La specifica IDL può essere compilata in una procedura client stub e memorizzata in una libreria.

Se il processo del client sa in anticipo che avrà bisogno di accedere a un determinato oggetto, verrà fatto il link del processo al codice del client stub dell’oggetto. La specifica IDL può anche essere compilata all’interno di una procedura scheletro usata sul lato server. Nel caso non si conoscano in anticipo gli oggetti che un processo ha bisogno di utilizzare, è possibile richiamarli dinamicamente, ma come ciò funzioni è al di là degli scopi della nostra analisi.

Quando si crea un oggetto CORBA, si crea anche un riferimento a esso e lo si resti- tuisce al processo che lo crea. Questo riferimento è il modo in cui il processo identifica l’oggetto per le successive chiamate ai suoi metodi. Il riferimento può essere passato ad altri processi o memorizzato in una directory di oggetti.

Per richiamare un metodo su un oggetto, un processo client deve prima acquisire un riferimento a quell’oggetto. Il riferimento può arrivare o direttamente dal processo creatore o, più probabilmente, cercandolo per nome o per funzione in alcuni tipi di directory. Una volta che il riferimento dell’oggetto è disponibile, il processo client organizza i parametri per le chiamate dei metodi in una struttura opportuna e poi contatta l’ORB del client. A sua volta, l’ORB del client manda un messaggio all’ORB del server, che richiama il metodo sull’oggetto. L’intero meccanismo è simile alle RPC.

La funzione degli ORB è quella di nascondere tutta la distribuzione a basso livello e i dettagli della comunicazione dal codice del client e del server. In particolare gli ORB nascondono al client la posizione del server, se il server sia un programma binario o uno script, su che hardware e su che sistema operativo è eseguito il server, se l’oggetto sia attualmente attivo e come i due ORB comunicano (per esempio, TCP/IP, RPC, memoria condivisa, e così via).

Nella prima versione di CORBA, il protocollo fra l’ORB del client e l’ORB del server non era specificato, per cui ogni fornitore di ORB usava un diverso protocollo e non ce n’erano due che potessero comunicare fra loro. Nella versione 2.0 fu specificato il protocollo. Per le comunicazioni via Internet il protocollo si chiama IIOP (Internet interorb protocol).

Per permettere l’utilizzo di oggetti non scritti per CORBA all’interno di sistemi CORBA, ogni oggetto può essere dotato di un adattatore dell’oggetto (object adapter). Si tratta di un “involucro” (wrapper ) che gestisce faccende come la registrazione dell’oggetto, la generazione dei riferimenti all’oggetto e l’attivazione dell’oggetto se è richiamato quando non è attivo. La sistemazione di tutte queste parti di CORBA è illustrata nella Figura 8.36.



Elementi principali di un sistema distribuito basato su CORBA. Le parti di CORBA sono raffigurate in grigio.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-39.png)

Un problema serio di CORBA è che ogni oggetto è posizionato su un solo server, il che significa che le prestazioni saranno disastrose per quegli oggetti molto usati sulle macchine client in giro per il mondo. In pratica CORBA funziona a un livello accettabile solo in sistemi a scala ridotta, come nel connettere processi su un singolo computer, una LAN o all’interno di una singola azienda.

&nbsp;
&nbsp;
&nbsp;

*Middleware basato sulla coordinazione*
====

Il nostro ultimo paradigma per un sistema distribuito è chiamato middleware basato sulla coordinazione. Cominceremo dal sistema Linda, un progetto di ricerca accademico che diede avvio all’intero movimento.

Linda è un originale sistema di comunicazione e sincronizzazione sviluppato all’Università di Yale da David Gelernter e il suo studente Nick Carriero (Carriero e Gelernter, 1968; Carriero e Gelernter, 1989 e Gelernter, 1985). In Linda, i processi indipendenti comunicano attraverso uno spazio delle tuple astratto. Lo spazio delle tuple è globale per l’intero sistema e i processi su qualsiasi macchina possono inserire le tuple nello spazio delle tuple o anche rimuoverle senza interessarsi di come o dove sono memorizzate. Per l’utente, lo spazio delle tuple appare come una grande memoria condivisa globale, come già abbiamo visto in diverse forme, come nella Figura 8.21(c).

Una tupla è come una struttura in C o in Java. È composta da uno o più campi, ciascuno dei quali è un valore di una certa tipologia supportato dal linguaggio base (Linda è implementato aggiungendo una libreria a un linguaggio esistente, come il C). Per il C-Linda, le tipologie dei campi includono interi, interi lunghi, numeri in virgola mobile, così come tipologie composte come array (incluse le stringhe) e strutture (ma non altre tuple). Diversamente dagli oggetti, le tuple sono dati puri; non hanno associato alcun metodo. La Figura 8.37 mostra tre esempi di tuple.



Esempio di Tupla

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-40.png)

Sono fornite quattro operazioni sulle tuple. La prima, out, pone una tupla nello spazio delle tuple. Per esempio,

>out(“abc”, 2, 5);

mette la tupla (“abc”, 2, 5) nello spazio delle tuple. I campi di out normalmente sono costanti, variabili o espressioni, come in

>out(“matrix-1”, i, j, 3.14);

che esegue l’output di una tupla con quattro campi, di cui il secondo e il terzo sono determinati dagli attuali valori delle variabili i e j.

Le tuple sono caricate dallo spazio delle tuple tramite la primitiva in. Sono indirizzate tramite il contenuto piuttosto che per nome o per indirizzo. I campi di in possono essere espressioni o parametri formali.

Considerate per esempio:

>in(“abc”, 2, ?i);

Questa operazione cerca nello spazio delle tuple una tupla composta dalla stringa “abc”, dall’intero 2 e da un terzo campo contenente qualunque intero (assumendo che i sia un intero). Se lo trova, la tupla è rimossa dallo spazio delle tuple e alla variabile i è assegnato il valore del terzo campo.

Il matching e la rimozione sono atomici, per cui se due processi eseguono la stessa operazione simultaneamente, solo uno dei due ci riuscirà, a meno che non siano presenti due o più tuple corrispondenti. Lo spazio delle tuple può anche contenere più copie della stessa tupla.

L’algoritmo di confronto usato da in è semplice. I campi della primitiva in, chiamati template, sono (concettualmente) confrontati con i campi corrispondenti di ogni tupla nello spazio delle tuple. Si verifica il matching quando si realizzano le seguenti tre condizioni:

-   Il template e la tupla devono avere lo stesso numero di campi;

-   le tipologie dei campi corrispondenti devono essere le stesse;ogni costante o variabile nel template deve trovare riscontro nel campo della sua tupla.

I parametri formali, indicati da un punto di domanda seguito da un nome di variabile o di tipo, non prendono parte a questo confronto (a eccezione del controllo del tipo), sebbene quelli che contengono un nome di variabile siano assegnati dopo un confronto con esito positivo.

Se non si trova alcuna tupla, il processo chiamante è sospeso finché un altro processo inserisce la tupla necessaria, al che il chiamante è risvegliato immediatamente e gli è data la nuova tupla. Il fatto che i processi si blocchino e si sblocchino automaticamente significa che se un processo sta per far l’output di una tupla e un altro ne sta per fare l’input, non importa chi va per primo. La sola differenza è che se in è eseguito prima di out ci sarà un piccolo ritardo prima che la tupla sia disponibile per la rimozione.

Il fatto che i processi si blocchino quando non c’è la tupla necessaria può essere sfruttato per più utilizzi. Può essere usato per esempio per implementare i semafori. Per creare o fare un up sul semaforo S, un processo può eseguire

>out(“semaphore S”);

Per fare un down

>in(“semaphore S”);

Lo stato del semaforo S è determinato dalla quantità di tuple (“semaphore S”) nello spazio delle tuple. Se non ce n’è alcuna, ogni tentativo di prelevarne una causerà un blocco, finché un altro processo non ne fornisca una.

Oltre a out e in, Linda ha anche un’altra primitiva, read, uguale a in eccetto che non rimuove la tupla dal suo spazio. C’è anche la primitiva eval, che fa sì che i suoi parametri siano valutati in parallelo e la tupla risultante sia messa nello spazio delle tuple. Questo meccanismo può essere usato per eseguire un calcolo arbitrario. È così che si creano i processi paralleli in Linda.

&nbsp;
&nbsp;
&nbsp;

    Publish/Subscribe

Il nostro prossimo esempio di modello basato sulla coordinazione fu ispirato da Linda ed è denominato publish/subscribe (Oki et al., 1993). È composto da un numero di processi connessi da una rete di trasmissione (broadcast). Ogni processo può essere un produttore di informazioni, un consumatore di informazioni o entrambe le cose.

Quando un produttore di informazioni ha un nuovo pezzo di informazione (per esempio il valore di un’azione), esegue il broadcast dell’informazione sulla rete come una tupla. Questa azione è detta pubblicazione (publishing). Ogni tupla contiene una linea gerarchica di argomenti contenente molteplici campi separati da dei punti. I processi interessati a determinate informazioni possono iscriversi (subscribe) a determinati argomenti, incluso l’utilizzo di wildcard nella linea degli argomenti. L’adesione avviene indicando al processo demone delle tuple sulla stessa macchina di monitorare le tuple pubblicate in base agli argomenti ricercati. Il publish/subscribe si implementa come nella Figura 8.38. Quando un processo ha una tupla da pubblicare, la emette sulla LAN locale. Il demone delle tuple copia nella RAM di ciascuna macchina tutte le tuple trasmesse. Verifica poi la linea degli argomenti per vedere quali processi vi siano interessati, inoltrandone una copia a chiunque lo sia. Le tuple possono anche essere trasmesse su una rete geografica o su Internet, tramite una macchina su ogni LAN che si comporta da router delle informazioni che raccoglie tutte le tuple pubblicate e le invia alle altre LAN per la ritrasmissione. Questo inoltro può essere fatto anche in modo intelligente, inviando una tupla a una LAN remota solo se in questa vi sia almeno un processo subscriber che voglia la tupla. Tutto questo necessita che i router (broker) si scambino le informazioni sui rispettivi subscriber.



Architettura publish/Subscribe

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/08-41.png)

Diversi tipi di semantica possono essere implementati, inclusa la consegna affidabile e la consegna garantita, anche a fronte di un crash. Nell’ultimo caso è necessario memorizzare le vecchie tuple nell’eventualità siano necessarie in seguito. Un modo per memorizzarle è quello di collegare al sistema un sistema di basi di dati e far sì che esegua il subscribe a tutte le tuple. Ciò può avvenire racchiudendo il sistema di basi di dati in un adattatore, per consentire a una base di dati esistente di funzionare con il modello publish/subscribe. Quando le tuple arrivano, l’adattatore le cattura e le mette nella base di dati.

Il modello publish/subscribe scollega completamente i produttori dai consumatori, come fa Linda. Tuttavia talvolta è utile sapere che altro c’è al di fuori. Questa informazione può essere acquisita pubblicando una tupla che fondamentalmente chiede: “Chi è interessato a x là fuori?” Le risposte tornano indietro sotto forma di tuple che dicono: “x interessa a me”.