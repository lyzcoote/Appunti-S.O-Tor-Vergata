# 3.1 Nessuna astrazione di memoria

La piÃ¹ semplice astrazione della memoria Ã¨ lâ€™assenza di astrazione. 

Dai primi mainframe fino ai primi personal computer, essi non avevano astrazione della memoria. 

Ogni programma vedeva semplicemente la memoria fisica. 

Quando un programma eseguiva unâ€™istruzione come `MOV REGISTER1,1000` il computer spostava semplicemente il contenuto della locazione di memoria fisica 1000 a REGISTER1. 

Con questo metodo perÃ², un altro programma avrebbe sovrascritto quello precendete.

Prendiamo adesso un esempio di una memoria con una migliore astrazione e gestione.


### **`Tre modi per organizzare la memoria con un sistema operativo e un processo utente.`**

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/03-01.png)

Nella FiguÂ­ra soprastante **sono illustrate tre varianti:**

-   **Il sistema operativo puÃ² trovarsi sul fondo della memoria, nella `RAM`** come mostrato nella FiguÂ­ra (`a`), 

-   **Il sistema operativo puÃ² trovarsi in cima alla memoria nella `ROM`** come mostrato nella Figura (`b`), 

-  **I driver dei dispositivi possono essere in cima alla memoria nella `ROM` e il resto del sistema nella `RAM` subito sotto**, come nella Figura (`c`). 

Il primo modello fu usato inizialmente sui mainframe e sui minicomputer, ma ormai Ã¨ utilizzato raramente. 

Il secondo modello Ã¨ usato su alcuni computer palmari e sistemi integrati. 

Il terzo modello Ã¨ stato usato sui primi personal computer, dove la parte del sistema nella `ROM` Ã¨ chiamata `BIOS`. 

&nbsp;
&nbsp;
&nbsp;

# 3.2 Spazio degli Indirizzi

Una soluzione migliore Ã¨ inventare una nuova astrazione per la memoria: **`lo spazio Â­degli indirizzi`.**

**CosÃ¬ come il concetto di processo crea una specie di CPU astratta per eseguire i programmi, lo spazio degli indirizzi crea una specie di memoria astratta per farci vivere i programmi.** 

>**DEF**: Uno spazio degli indirizzi Ã¨ lâ€™insieme degli indirizzi che un procesÂ­so puÃ² usare per indirizzare la memoria.

**Ogni processo ha il suo spazio degli indirizzi Â­personale, Â­indipendente da quello appartenente ad altri processi** (a eccezione di alcune circostanze speciali in cui i processi vogliono condividere i loro spazi degli indirizzi).

**Spazio di indirizzamento della CPU = Max quantitÃ  di celle indirizzabili = 2Â°a (dove a Ã¨ la dimensione in bit degli indirizzi)**

>**E.g:** Una `CPU` a `32 bit` ha uno spazio degli indirizzi massimo equivalente a `4294967295`

&nbsp;
&nbsp;
&nbsp;

*Registri base e registri limite*
====

Ãˆ necessario garantire che ogni processo acceda solo alla sua area di memoria (a meno di condivisioni volute).

Quindi si utilizzano due registri:

-   **`Registro base:`**

    -   *Contiene il piÃ¹ piccolo indirizzo fisico ammesso (di solito `0`)*


-   **`Registro limite:`**

    -   *Contiene la dimensione dellâ€™intervallo ammesso*

        -   ***Solo il SO puÃ² accedere a questi registri ed impedisce ai programmi utente di modificarli*** 


### **`Esempio di un layout di memroria`**

![alt text](https://i.imgur.com/7b2Ck64.png)

&nbsp;
&nbsp;
&nbsp;

*Separazione degli spazi di indirizzamento*
====


**Quando un processo utente cerca di accedere ad un indirizzo la CPU lo confronta con i valori dei due registri.**

**Ogni tentativo da parte di un processo utente di accedere ad unâ€™area non concessa della memoria porta ad unâ€™eccezione:**

-   Il controllo viene restituito al SO

-   Passaggio da modalitÃ  utente a modalitÃ  Kernel

**Il SO non ha limiti sulle aree di memoria a cui puÃ² accedere.**

&nbsp;
&nbsp;
&nbsp;

*Swapping*
====

**Un processo puÃ² essere temporaneamente scambiato (swapped), ovvero spostato dalla memoria centrale ad una memoria secondaria (area di swap) e poi in seguito riportato interamente in memoria centrale per continuarne lâ€™esecuzione.**

**Questa tecnica viene chiamata `Swapping`**

>**NOTA:** Come Memoria Secondaria si intende un unitÃ  di memoriazione locale abbastanza veloce e capiente, dato che de accogliere le copie di tutte le immagini della memoria centrale per tutti gli utenti.

### **`Esempio di un layout di swapping`**

![alt text](https://i.imgur.com/xxhz9rz.png)

**Inoltre, lo swapping permette di gestire piÃ¹ processi di quelli che fisicamente sarebbero caricabili in memoria.**

**Il periodico scambio tra processi in memoria centrale e secondaria (`swapping`) Ã¨ controllato dallo scheduler a medio termine.**

**Lo swapping Ã¨ molto comune nei sistemi con schedulatore Round Robin.**

-   Il processo che finisce il quanto di tempo subisce lo swap-out.

**`Roll out`, `roll in` Ã¨ una variante dello swapping usata per algoritmi di schedulazione basati sulla prioritÃ .**

-   ***un processo a bassa prioritÃ  Ã¨ scambiato con un processo ad alta prioritÃ .***, in modo che questâ€™ultimo possa essere caricato ed eseguito.

La zona di memoria in cui i processi che subiscono lo swap-in vengono spostati dipende dalla fase in cui gli indirizzi logici vengono associati a quelli fisici.

**Lo swapping deve tenere conto anche di possibili I/O.**

-   Se i processi sono impegnati in un I/O asincrono non possono essere avvicendati.

&nbsp;
&nbsp;
&nbsp;

# 3.3 Memoria Virtuale

**La memoria virtuale Ã¨ un'architettura di sistema capace di simulare uno spazio di memoria centrale (memoria primaria) maggiore di quello fisicamente presente o disponibile, dando l'illusione all'utente di un enorme quantitativo di memoria.**

**Il sistema operativo usando una combinazione di hardware e software, mappa gli indirizzi di memoria usati da un programma, chiamati indirizzi virtuali, in indirizzi fisici.** 

**La memoria principale, dal punto di vista di un processo, appare come uno spazio di indirizzi (o una lista di segmenti) contiguo.**

Il sistema operativo gestisce lo spazio virtuale e l'assegnamento di memoria fisica a memoria virtuale. 

**La traduzione di indirizzi Ã¨ fatta da un hardware presente nella CPU, comunemente chiamato `MMU` (*Memory Managment Unit*), che traduce i vari indirizzi.**

Software presente all'interno del sistema operativo puÃ² estendere queste funzionalitÃ  per offrire uno spazio virtuale che eccede quello della memoria fisica, indirizzando cosÃ¬ piÃ¹ memoria di quella fisicamente presente nel computer.

**La memoria virtuale funziona bene in un sistema multiprogrammazione**, con bit e pezzi di molti programmi contemporaneamente in memoria. 

**Mentre un programma Ã¨ in attesa che un suo pezzo sia letto, la CPU puÃ² essere assegnata a un altro processo.**

&nbsp;
&nbsp;
&nbsp;

*Paginazione*
====

**I meccanismi a partizionamento fisso/dinamico non sono efficienti nellâ€™uso della memoria.**

**La paginazione Ã¨ lâ€™approccio utilizzato nei SO moderni per:** 

-   *Ridurre il fenomeno di frammentazione esterna allocando ai processi spazio di memoria non contiguo*.

-   *Si tiene in memoria solo una porzione del programma*.

    -   *Aumento del numero dei processi che possono essere contemporaneamente presenti in memoria*.

-   *La possibilitÃ  di eseguire un processo piÃ¹ grande della memoria disponibile (memoria virtuale)*.

**Suddivide la memoria fisica (memoria centrale) in blocchi di frame della stessa dimensione (una potenza di `2`, fra `512 byte` e `16 MB`)**.

-   ***Lo spazio degli indirizzi fisici puÃ² essere non contiguo***.

Divide la memoria logica in blocchi delle stesse dimensioni dei frame chiamati pagine .

-  *Il processo Ã¨ sempre allocato allâ€™interno della memoria logica in uno **spazio contiguo***.

Per eseguire un processo di dimensione di n pagine, bisogna trovare n frame liberi e caricare il programma.

Il SO imposta una tabella delle pagine per tradurre gli indirizzi logici in indirizzi fisici.

&nbsp;
&nbsp;
&nbsp;

Ogni indirizzo logico generato dalla CPU Ã¨ diviso in due parti: 

-   Numero di pagina (p):

    -   Usato come indice nella tabella delle pagine che contiene lâ€™indirizzo di base di ogni frame nella memoria fisica.

-   Spiazzamento nella pagina (d):

    -   Combinato con lâ€™indirizzo di base per calcolare lâ€™indirizzo di memoria fisica che viene mandato allâ€™unitÃ  di memoria centrale.


### **`Esempio di un layout di un indirizzo logico`**

![alt text](https://i.imgur.com/E7P5Z6v.png)
****


    Esempio di paginazione

**La tabella delle pagine associa lâ€™indirizzo di una pagina logica al corrispettivo indirizzo della pagina nella memoria fisica**

![alt text](https://i.imgur.com/3dAFdaY.png)

**Le aree di memoria dei processi possono essere interfogliate**

![alt text](https://i.imgur.com/8znaQhb.png)

****

&nbsp;
&nbsp;
&nbsp;

La dimensione di una pagina varia dai 512 byte ai 16MB

La dimensione della pagina Ã¨ definita dallâ€™architettura del sistema ed Ã¨ in genere una potenza di 2

-   PerchÃ© semplifica la traduzione degli indirizzi

Infatti, se lo spazio logico di indirizzamento Ã¨ `2^m` e la dimensione di pagina Ã¨ `2^n unitÃ `, allora: 

-   `m-n bi`t piÃ¹ significativi dellâ€™ind. logico **indicano la `pagina p`**

-   `n bit` meno significativi dellâ€™ind. logico **indicano lo scostamento di `pagina d`**

![alt text](https://i.imgur.com/H2YEjwS.png)

&nbsp;
&nbsp;
&nbsp;

*Tabella dei frame*
====

Oltre alla **tabella delle pagine** (logiche) di ciascun processo, **il SO mantiene unâ€™unica tabella dei frame** (pagine fisiche): 

-   Contiene un elemento per ogni frame, che indica se questo Ã¨ libero o allocato, e (se allocato) a quale pagina di quale processo o processi.

&nbsp;
&nbsp;
&nbsp;

*Implementazione della tabella delle pagine*
====

**La maggior parte dei sistemi usa una tabella delle pagine per ogni processo.**

-   **`Prima soluzione:`**

    -   **Si usa uno specifico insieme di registri per salvare la tabella**.

    -   **Durante il context switch i valori della tabella delle pagine del processo vengono caricate nei registri**.

    -   *Molto veloce*.

    -   **Ma va bene solo per tabelle con pochi elementi** (`256` circa, quando tipicamente ne servono `1.000.000`).

-   **`Seconda soluzione:`**

    -   **La tabella delle pagine viene mantenuta in memoria centrale** .

    -   **Un registro chiamato `PTBR`** (page-table base register) **punta alla tabella del processo corrente**.

    -   *Cambiare tabella delle pagine significa cambiare valore del registro*.

    -   ðŸ”´ Problema: 
    
        -   *Per accedere ad un dato occorrono due accessi alla memoria centrale:*

            -   1 per la tabella delle pagine.

            -   1 per il byte stesso.

    -   **Lâ€™accesso alla memoria Ã¨ rallentato di un fattore 2** (*sarebbe preferibile usare lo swapping*) .

-   **`Terza soluzione:`**

    -   **Si utilizza una cache associativa: `TLB`** (*translation look-aside buffer*).

    -   **Associa ad una chiave un valore**:

        -   *Chiave*: 
        
            -   Indirizzo logico .
            
        -   *Valore*: 

            -   Indirizzo fisico.

        -   **Molto rapida ma anche costosa e piccola** (*max `1024` elementi*).

    -  **I record possono essere scritti e sovrascritti**.

    -  **Ma possono anche essere vincolati** (***non modificabili***) .

    -   **Utilizzo:**

        -   *La `TLB` contiene una piccola parte delle righe della tabella delle pagine*.

&nbsp;
&nbsp;
&nbsp;


![alt text](https://i.imgur.com/bkSN7BT.png)

**Dato un indirizzo logico lo si passa alla `TLB`, se essa contiene tale chiave restituisce lâ€™indirizzo fisico**

Altrimenti (`TLB Miss`) si cerca nella tabella residente in memoria centrale:

-   **Si copiano poi i due indirizzi nella `TLB` in modo da velocizzare accessi futuri**

-   *Se la tabella Ã¨ piena si sceglie quale record togliere secondo diversi criteri* 
>**E.g:** Elemento usato meno di recente, casuale

![alt text](https://i.imgur.com/LC31WbJ.png)

&nbsp;
&nbsp;
&nbsp;

# 3.4 Algoritmi di sostituzione delle pagine

Elenco algortimi disponibili: `Ottimale, NRU, FIFO, Seconda chance, Clock, LRU, NFU, Aging, Working Set, WSClock`

**Il criterio di valutazione Ã¨ il numero di `page fault`. Tanto Ã¨ minore il numero di page fault, tanto piÃ¹ efficace Ã¨ l'algoritmo.**

&nbsp;
&nbsp;
&nbsp;

*Ottimale*
====

**L'algoritmo Ottimale (`OPT`) Ã¨ un algoritmo teorico, impossibile da implementare, in quanto richiede una conoscenza perfetta degli eventi futuri da parte del sistema operativo**, l'OPT, infatti, seleziona la pagina che (in futuro) non verrÃ  usata per il periodo di tempo piÃ¹ lungo. 

**L'algoritmo ottimale viene impiegato fondamentalmente come algoritmo di riferimento**, *utile per misurare e giudicare le prestazioni* (tramite comparazione) *degli algoritmi implementabili praticamente*, come l'algoritmo di sostituzione `FIFO` o quello `LRU`.

&nbsp;
&nbsp;
&nbsp;

*NRU*
====

Lâ€™algoritmo `NRU` (*Not Recently Used*) **suddivide le pagine in quattro classi che dipendono dallo stato dei bit `R` e `M`.** **Viene scelta una pagina a caso fra le pagine della classe con la numerazione Â­inferiore.** **Ãˆ un algoritmo semplice da implementare, ma molto grezzo (non efficente).**

&nbsp;
&nbsp;
&nbsp;

*FIFO*
====

Un algoritmo di paginazione con basso overhead Ã¨ il `FIFO` (*first-in, first-out*). 

>**E.g**: Consideriamo *un supermercato che abbia abbastanza scaffali da poter esporre esattamente un numero `k` di prodotti diversi*. Un bel giorno, *unâ€™azienda introduce un nuovo prodotto alimentare* â€“ biologico, istantaneo, essiccato, che puÃ² essere riportato allo stato naturale nel forno a microonde. *Ha un successo cosÃ¬ immediato che il supermercato deve disfarsi di un vecchio prodotto per fornirsene in magazzino.*

*Una possibilitÃ  Ã¨ di rintracciare il prodotto che il supermercato ha in magazzino da piÃ¹ tempo* (probabilmente qualcosa che ha iniziato a vendere molti anni prima) *ed eliminarlo poichÃ© nessuno se ne interessa piÃ¹*

Effettivamente *il supermercato tiene una lista collegata di tutti i prodotti in vendita nellâ€™ordine in cui sono stati introdotti*. 

**Quello nuovo va in fondo alla lista; il primo della lista Ã¨ eliminato.**

**Questo stesso esempio Ã¨ applicabile anche come algoritmo di sostituzione delle pagine.** 

*Il sistema operativo tiene una lista delle pagine attualmente in memoria, con lâ€™arrivo piÃ¹ recente in coda e il piÃ¹ vecchio in testa.*

**A un `page fault`, la pagina di testa Ã¨ rimossa e la nuova aggiunta in coda allâ€™elenco**.

**Quando il `FIFO` Ã¨ applicato ai supermercati rimuove articoli quali la cera per i baffi, ma potrebbe anche rimuovere farina, sale o burro.** 

Quando applicato nei computer sorge lo stesso problema. 

**Per questo motivo il `FIFO` Ã¨ raramente usato nella sua forma piÃ¹ rigida.**

&nbsp;
&nbsp;
&nbsp;

*Seconda Canche*
====

**Lâ€™algoritmo `seconda chance` Ã¨ una modifica del `FIFO` che controlla se la pagina Ã¨ in uso prima di rimuoverla.** 

**Se lo Ã¨, la pagina Ã¨ risparmiata. Questa modifica incrementa enormemente le prestazioni.**

&nbsp;
&nbsp;
&nbsp;

*Clock*
====

**Lâ€™algoritmo `Clock` Ã¨ semplicemente una diversa implementazione del `Seconda chance`. Ha le stesse proprietÃ  prestazionali, ma impiega leggermente meno tempo a eseguire lâ€™algoritmo.**

**Ovvero usa un approccio migliore, cioÃ¨ quello di tenere tutti i frame su una lista circolare a forma di orologio, come mostrato nella Figura sottostante.** 

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/03-16.png)

**La lancetta indica la pagina piÃ¹ vecchia.** 

**Questo processo Ã¨ ripetuto finchÃ© non viene trovata una pagina con `R = 0`.**

&nbsp;
&nbsp;
&nbsp;

*LRU*
====

*Una buona approssimazione dellâ€™algoritmo ottimale si basa sullâ€™osservazione che le pagine usate piÃ¹ frequentemente nelle ultime istruzioni lo saranno anche nelle successive. Al contrario quelle inutilizzate da anni lo resteranno ancora per molto.*

Questa strategia si chiama paginazione `LRU` (*least recently used*). 

*Sebbene questo algoritmo sia teoricamente fattibile, non Ã¨ economico.* **Per implementare pienamente `lâ€™LRU` Ã¨ necessario mantenere una lista collegata di tutte le pagine in memoria, con davanti quelle piÃ¹ usate e dietro quelle meno usate.** 

**La difficoltÃ  sta nel fatto che lâ€™elenco deve essere aggiornato a ogni riferimento alla memoria. Trovare una pagina in memoria, cancellarla e poi portarla davanti Ã¨ unâ€™operazione che costa del tempo, anche se eseguita nellâ€™hardware (dando per assunto che un hardware del genere sia realizzabile).**

Lâ€™LRU Ã¨ un algoritmo eccellente, ma non puÃ² essere implementato senza un hardware speciale.

&nbsp;
&nbsp;
&nbsp;


*Working Set*
====

**Si prevede il set di pagine di cui il processo da caricare ha bisogno per la prossima fase di esecuzione.**

**Lâ€™algoritmo del `working set` fornisce prestazioni ragionevoli, ma Ã¨ in un certo modo costoso da implementare.**

&nbsp;
&nbsp;
&nbsp;


*WSClock*
====

**L'algortimo `WSClock` Ã¨ un mix tra il `Working Set` e il `Clock`. Grazie alla sua semplicitÃ  di implementazione e alle buone prestazioni, nella pratica Ã¨ diffusamente usato**.

*La struttura dati necessaria Ã¨ una lista circolare di frame,* **come nellâ€™algoritmo `Clock`** *e coÂ­me illustrato nella Figura (`a`).*

*Inizialmente questo elenco Ã¨ vuoto. Quando Ã¨ caricata la priÂ­ma pagina, essa viene aggiunta allâ€™elenco. Nel venir aggiunte piÃ¹ pagine, queste vanno nelÂ­lâ€™eÂ­Â­lenco a formare un cerchio.* 

*Ogni voce contiene il campo Tempo di ultimo utilizzo* (*time of last use*) *dallâ€™algoritmo base del `working set`, cosÃ¬ come il bit `R`* (*mostrato*) *e il bit `M`* (*non Â­mostrato*)*.*

**Come nellâ€™algoritmo `Clock`, a ogni page fault quella indicata dalla lancetta dellâ€™orologio Ã¨ esaminata per prima. Se il bit `R Ã¨ 1`, la pagina Ã¨ stata usata nel ciclo del clock, quindi non Ã¨ la candidata ideale alla rimozione. Il bit `R` Ã¨ impostato a `0`, la lancetta avanza alla pagina successiva e lâ€™algoritmo rieseguito per la nuova pagina. La situazione dopo questa sequenza Ã¨ mostrata nella Figura (`b`).**

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/03-21.png)

**Consideriamo adesso che cosa accade se la pagina indicata ha `R = 0`, come mostrato nella Figura (`c`)**. 

-   **Se almeno un pageout Ã¨ stato schedulato, si continua a girare** (aspettando che le pagine schedulate vengano salvate).

-   **Altrimenti, significa che tutte le pagine sono nel working set**. Soluzione semplice: 
    
    -   *Si rimpiazza una qualsiasi pagina pulita.*

-   **Se non ci sono neanche pagine pulite, si rimpiazza la pagina corrente.**


&nbsp;
&nbsp;
&nbsp;


*Riepilogo*
====

| **Algortimo**  	| **Commento**                                                        	|
|----------------	|---------------------------------------------------------------------	|
| Ottimale       	| Non implementabile, ma utile come indice di confronto e valutazione 	|
| NRU            	| Approssimazione molto rozza dellâ€™LRU                                	|
| FIFO           	| Potrebbe eliminare pagine importanti                                	|
| Seconda Chance 	| Deciso miglioramento rispetto al FIFO                               	|
| Clock          	| Realistico                                                          	|
| LRU            	| Eccellente, ma difficile da implementare con precisione             	|
| NFU            	| Approssimazione abbastanza rozza dellâ€™LRU                           	|
| Aging          	| Algoritmo efficiente che approssima bene lâ€™LRU                      	|
| Working set    	| Piuttosto dispendioso da implementare                               	|
| WSClock        	| Algoritmo efficiente e buono                                        	|


