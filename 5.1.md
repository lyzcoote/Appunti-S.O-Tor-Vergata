# 5.1 Principi hardware dell’I/O

*Dispositivi di I/O*
====

I dispositivi di I/O possono essere sommariamente suddivisi in due categorie: **dispositivi a blocchi e dispositivi a caratteri**. 

-   `Dispositivi a blocchi`:
    -   Un dispositivo a blocchi è quello che **archivia informazioni in blocchi di dimensioni fisse, ognuno con il proprio indirizzo.** 

    -   L’intervallo comune delle **dimensioni dei blocchi va da `512` a `32.768 byte`.** 
    **Tutti i trasferimenti sono in unità di uno o più blocchi (consecutivi) interi.**

    -   I dispositivi che ricadono i questa categoria sono: **dischi fissi, dischi Blu-ray e penne USB.**

    -   >**NOTA:**  La caratteristica essenziale di un dispositivo a blocchi è che **ciascun blocco può essere letto o scritto indipendentemente da tutti gli altri**.

-   `Dispositivi a caratteri`:
    -   Un dispositivo a caratteri **rilascia o accetta un flusso di caratteri, senza alcuna struttura a blocchi.**

    -   I dispositivi che ricadono i questa categoria sono: **stampanti, interfacce di rete, tastiere, mouse, ect..**

>**NOTA:** Alcuni dispositivi però non ricadono in questo schema.

Tipo **`i clock`**, **non sono indirizzabili a blocchi e non generano né accettano flussi di caratteri: tutto ciò che fanno è produrre interrupt a intervalli ben definiti.**

&nbsp;
&nbsp;
&nbsp;

**I dispositivi di I/O possono avere velocità molto diverse.**

### **`Velocità trasferimento dati di alcuni dispositivi tipici e bus.`**

| **Dispositivo**      	| **Velocità trasferimento dati** 	|
|----------------------	|---------------------------------	|
| Tastiera             	| 10 byte/s                       	|
| Mouse                	| 100 byte/s                      	|
| Modem a 56k          	| 7 KB/s                          	|
| Scanner              	| 1 MB/s                          	|
| Videocamera Digitale 	| 3,5 MB/s                        	|
| Disco Blu-Ray 4x     	| 18 MB/s                         	|
| 801.11n Wireless     	| 37,5 MB/s                       	|
| USB 2.0              	| 60 MB/s                         	|
| Firewire 800         	| 100 MB/s                        	|
| Gigabit Ethernet     	| 125 MB/s                        	|
| Disco SATA 3         	| 600 MB/s                        	|
| USB 3.0              	| 625 MB/s                        	|
| Bus SCSI Ultra 5     	| 640 MB/s                        	|
| Bus PCIe 3.0 1x      	| 985 MB/s                        	|
| Bus ThunderBolt 2    	| 2,5 GB/s                        	|
| Bus PCIe 3.0 16x     	| 32 GB/s                         	|

&nbsp;
&nbsp;
&nbsp;

*Controller dei dispositivi*
======

**I dispositivi di I/O consistono tipicamente di una componente meccanica e di una elettronica**.
Spesso è possibile separare queste due parti per **fornire una progettazione più mo­dulare e generale.** 

La componente elettronica è detta **controller del dispositivo (`device controller`)**.
 
La parte meccanica è il **dispositivo stesso** (Es: Un Disco Meccanico).

La scheda del controller presenta spesso un connettore in cui inserire un cavo che si collega al dispositivo stesso.

Molte industrie producono unità disco che **si connettono alle interfacce `SATA, SCSI, USB, ThunderBolt` o `FireWire` (`IEEE 1394`).**

L’interfaccia fra il controller e il dispositivo è generalmente di **livello veramente basso**.

Il lavoro del controller è **convertire il flusso seriale di bit in un blocco di byte ed eseguire ogni necessaria correzione di errore.** 

### **`Esempio di Controller in un HDD`**
![alt text](https://www.hddzone.com/blog/images/M5.jpg)

&nbsp;
&nbsp;
&nbsp;

*Input/output mappato in memoria*
======

**Ogni controller dispone di pochi registri usati per le comunicazioni con la CPU.**

Nello scrivere in questi registri **il sistema operativo comanda al dispositivo di inviare dati, accettarli**, porsi in stato di acceso o spento o eseguire qualche altra azione. 

**Leggendo da questi registri, il sistema operativo apprende quale sia lo stato del dispositivo**, se sia predisposto ad accettare un nuovo comando e così via.

Oltre ai registri di controllo, **molti dispositivi hanno un buffer di dati su cui il sistema operativo può scrivere e leggere**.

>**E.g:** **La RAM video (`VRAM`) è fondamentalmente un `buffer di dati`**, a disposizione dei programmi o del sistema operativo per lettura/scrittura, necessario per la visualizzazione.

La questione che sorge è come la CPU comunichi con i registri di controllo e i buffer dei dati del dispositivo.

Esistono due alternative: **I/O mappato su porte(`Port-mapped I/O`) e I/O mappato in memoria (`Memory-mapped I/O`)**

-   `I/O Mappato su Porte`:

    -   Usa lo stesso bus per indirizzare sia la memoria che i dispositivi di I/O, e le stesse istruzioni della CPU utilizzate per leggere e scrivere la memoria sono utilizzate anche per accedere ai dispositivi di I/O. 
    
    -   Per poter alloggiare i dispositivi di I/O, aree di spazio indirizzabile dalla CPU devono essere riservate per l'I/O invece che essere usate per la memoria. Questa suddivisione non deve necessariamente essere permanente, per esempio si può effettuare lo switch tra I/O e memoria. 
    
    -   I dispositivi di I/O controllano il bus indirizzi della CPU e rispondono ad ogni accesso allo spazio indirizzi a loro assegnato, mappando l'indirizzo nei loro registri hardware.

-   `I/O Mappato in Memoria`:

    -   Usa una speciale classe di istruzioni specifiche per l'esecuzione dell'input/output.

    -   I dispositivi di I/O hanno uno spazio indirizzi separato da quello della memoria, ottenuto tramite un extra "I/O" pin sull'interfaccia fisica della CPU oppure tramite un bus dedicato.

### **`Esempio di Port-mapped I/O e Memory-mapped I/O`**
![alt text](https://i.imgur.com/IqwtLX8.png)

&nbsp;
&nbsp;
&nbsp;

**I due schemi per indirizzare i controller presentano punti di forza e punti deboli diversi.**


### **`Vantaggi e Svantaggi`**
-   `I/O Mappato su Porte`:
    
    -   **Il port-mapped I/O separa l'accesso a ingressi/uscite dagli accessi alla memoria, tutto lo spazio di indirizzi può essere usato per la memoria.**

    -   **L'accesso all'I/O è ovvio anche per una persona che legga un programma scritto in assembly, dato che si utilizzano istruzioni speciali.**
    

-   `I/O Mappato in Memoria`:

    -   **La CPU richiede meno logica interna ed è di conseguenza più economica, veloce e facile da costruire.**

    -   **Non serve alcun meccanismo di protezione speciale per evitare che i processi utente eseguano l’I/O**.

    -   **Ogni istruzione che può referenziare della memoria può anche referenziare dei registri di controllo.**

&nbsp;
&nbsp;
&nbsp;

Nella progettazione dei computer i compromessi sono inevitabili ed è così anche in questo caso. Anche l’I/O mappato in memoria ha i suoi svantaggi. Primo, la maggior parte dei computer moderni ha una qualche forma di cache delle parole della memoria. Gestire la cache di un registro di controllo potrebbe avere effetti disastrosi. Considerate il precedente ciclo in codice assembly nel caso di una cache. La prima referenza a PORT_4 ne causerebbe la messa in cache. Tutte le referenze successive prenderebbero il valore dalla cache senza più interrogare il dispositivo. Anche qualora esso diventasse disponibile, il software non se ne accorgerebbe, causando un ciclo infinito.

Per evitare questa situazione nel caso di dispositivi mappati in memoria, l’hardware deve avere la capacità di disabilitare in maniera selettiva la cache, per esempio a seconda delle pagine. Questa proprietà aggiunge un’ulteriore complessità sia all’hardware sia al sistema operativo, che deve gestire questa cache selettiva.

Secondo, se siamo in presenza di un solo spazio degli indirizzi, tutti i moduli di memoria e tutti i dispositivi di I/O devono esaminare tutte le referenze di memoria per vedere a quali rispondere. Se il computer ha un singolo bus, come nella Figura 5.3(a), è semplice fare in modo che ciascuno controlli tutti gli indirizzi.

![alt text](https://i.imgur.com/uREmHRI.png)

Tuttavia, la tendenza dei personal computer moderni è quella di avere un bus dedicato di memoria ad alta velocità, come nella Figura 5.3(b). Questo bus è appositamente costruito per ottimizzare le prestazioni della memoria, senza scendere ad alcun compromesso per il bene dei dispositivi di I/O lenti. I sistemi x86 possono avere più bus (memoria, PCIe, SCSI, USB), come illustrato nella Figura 1.12.

Il problema di avere un bus di memoria separato su una macchina che usa i dispositivi mappati in memoria è che i dispositivi di I/O non hanno modo di vedere gli indirizzi di memoria quando vanno sul bus della memoria e così non hanno modo di rispondergli. Inoltre, per rendere funzionanti i dispositivi mappati in memoria su un sistema con più di un bus sono state prese misure speciali. Una possibilità è quella di inviare prima alla memoria tutte le referenze di memoria. Se la memoria non risponde, la CPU prova gli altri bus. Questa progettazione può funzionare, ma richiede un’ulteriore complessità hardware.

Una seconda visione possibile è mettere un dispositivo filtro sul bus di memoria, che intercetti tutti gli indirizzi che interessano potenzialmente dei dispositivi di I/O. Il problema che si presenta è che i dispositivi di I/O potrebbero non essere in grado di eseguire le richieste alla velocità cui invece è in grado di rispondere la memoria.

Una terza via possibile, che è quella utilizzata sulla configurazione della Figu­ra 1.12, è filtrare gli indirizzi sul chip del bridge PCI. Questo chip contiene un intervallo di indirizzi che è precaricato al momento dell’avvio. Per esempio, l’intervallo da 640K a 1M può essere contrassegnato come un intervallo non di memoria. Gli indirizzi che rientrano in uno di questi intervalli contrassegnati come non di memoria sono inoltrati sul bus PCI invece che alla memoria. Lo svantaggio di questo sistema è che occorre calcolare, al momento dell’avvio, quali indirizzi di memoria non lo sono realmente. Quindi ogni modello ha i suoi pro e i suoi contro, compromessi e compensazioni.

&nbsp;
&nbsp;
&nbsp;

*Direct memory access (DMA)*
======
