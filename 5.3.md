# 5.3 Livelli del software di I/O

Il software di I/O è generalmente organizzato in quattro livelli, come mostrato nella Figura 5.11, ciascuno dei quali ha una funzione ben definita da eseguire e un’interfaccia ben definita verso i livelli adiacenti. La funzionalità e le interfacce sono diverse da sistema a sistema, così l’analisi seguente, che esamina tutti i livelli partendo dal basso, non è specifica di una macchina.


Livelli del sistema del software per l’I/O.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-11.png)

&nbsp;
&nbsp;
&nbsp;

*Gestori degli interrupt*
====

Quando arriva un interrupt, la CPU deve mandare in esecuzione l'`ISR `(`Interrupt Service Routine`) predisposta ad hoc dal programmatore per quel particolare interrupt. 

Affinché il meccanismo dell'interruzione funzioni correttamente, è necessario che tutte le azioni svolte dall'ISR siano trasparenti rispetto al programma interrotto, cioè che al termine venga ripristinato tutto come era prima dell'interrupt, in altre parole, che la ISR sia perfettamente rientrante (attraverso l'istruzione Return).

Per fare ciò bisogna che la CPU, prima di mandare in esecuzione l'ISR, faccia una commutazione di contesto, ovvero salvi tutto quello che stava facendo (cioè il suo contesto attuale), ed alla fine dell'ISR lo ripristini com'era.

L'interrupt va gestito rapidamente, e quindi non va perso tempo per salvare tutto il contesto attuale (variabili, stato del programma, l'immagine sullo schermo ecc..) ma solo quello che effettivamente verrà modificato dall'ISR. D'altra parte la CPU non sa esattamente che cosa modificherà l'ISR e quindi non può conoscere a priori cosa salvare. Quindi quando si verifica un'interruzione l'hardware deve provvedere ad effettuare la commutazione di almeno la seguente porzione del contesto:

Il registro PC (Program counter)
Il registro che definisce lo stato dell'interrompibilità del processore
Nei moderni sistemi i gestori di interrupt sono divisi in due parti:

gestori di primo livello (FLIH, First-Level Interrupt Handler)
gestori di secondo livello (SLIH, Second-Level Interrupt Handlers)
I gestori di primo livello (FLIH) funzionano nello stesso modo delle vecchie routine di interrupt. In risposta ad un interrupt avviene una commutazione di contesto e il codice per gestire l'interrupt viene caricato in memoria ed eseguito. Il compito del FLIH, comunque, non è quello di gestire l'interrupt, bensì quello di schedulare la successiva esecuzione del gestore di secondo livello (SLIH), nonché quello di tenere traccia e di memorizzare tutte le eventuali informazioni importanti che fossero disponibili soltanto nel momento in cui si verifica l'interrupt.

Il gestore SLIH rimane nella coda pronti del sistema operativo finché, quando si rende disponibile tempo macchina del processore, arriva il suo turno di esecuzione, e può essere eseguito il codice per gestire l'evento che ha innescato l'interrupt.




Anche se l’I/O programmato è talvolta utile, per la maggior parte dell’I/O gli interrupt sono una spiacevole eventualità che non può essere evitata. 

Dovrebbero rimanere nascosti, nelle più profonde viscere del sistema operativo, in modo che il sistema operativo ne sia a conoscenza il meno possibile. 

Il miglior modo per nasconderli è fare in mo­do che il driver che avvia un’operazione di I/O si blocchi finché l’I/O non è termina­to e si verifica l’interrupt. 

Il driver può bloccarsi facendo per esempio una down su un semafo­ro, una wait su una variabile condizione, una receive su un messaggio o qualcosa di simile. 

Quando si verifica l’interrupt, la procedura fa quanto deve per gestirlo. 

Quindi può sbloccare il driver che l’ha fatto partire. 

In alcuni casi si completerà con una up su un semaforo. In altri invierà una signal su una variabile condizione in un monitor. 

In altri ancora invierà un messaggio al driver bloccato. In ogni caso l’effetto dell’interrupt sarà che un driver in precedenza bloccato potrà essere adesso in esecuzione. 

Questo modello funziona meglio se i driver sono strutturati come processi kernel, con i loro stati, stack e contatori di programma personali.

Naturalmente la realtà non è così semplice. L’elaborazione di un interrupt non si esaurisce nel prendere l’interrupt, fare una up su un qualche semaforo e poi eseguire un’istruzione IRET per ritornare dall’interrupt al processo precedente. È richiesto molto più lavoro da parte del sistema operativo, sintetizzato nei passi seguenti. Va fatto notare che i dettagli variano molto da sistema a sistema, quindi alcuni dei punti che seguono potrebbero non essere necessari su una determinata macchina e altri non elencati invece­ risultare necessari, Infine, su certe macchine alcuni passaggi potrebbero essere in ordine ­differente.

-   Salvataggio di tutti i registri (incluso il PSW) non ancora salvati dall’interrupt hardware.

-   Impostazione di un contesto per la procedura di servizio dell’interrupt.

-   Impostazione di uno stack per la procedura di servizio dell’interrupt.

-   Avviso al controller degli interrupt. Qualora manchi il controller centralizzato degli interrupt, riabilitazione degli interrupt.

-   Copia dei registri da dove erano stati salvati (eventualmente qualche stack) nella tabella dei processi.

-   Esecuzione della procedura di servizio dell’interrupt. Estrarrà informazioni dai registri del controller del dispositivo che ha generato l’interrupt.

-   Scelta di quale processo eseguire come successivo. Se l’interrupt ha fatto sì che qualche processo a priorità alta che era bloccato sia ora diventato pronto, potrebbe essere selezionato adesso per l’esecuzione.

-   Impostazione del contesto della MMU per il processo successivo da eseguire. Potrebbe essere anche necessario impostare il TLB.

-   Caricamento dei nuovi registri del processo, incluso il suo PSW.

-   Avvio dell’esecuzione del nuovo processo.

Come si può vedere, l’elaborazione di un interrupt è tutto fuorché banale. Richiede anche un numero considerevole di istruzioni CPU, specialmente su macchine in cui è presente la memoria virtuale; devono inoltre essere impostate le tabelle delle pagine o memorizzato lo stato della MMU (per esempio i bit R e M). Su alcune macchine possono inoltre dover essere gestiti il TLB e la cache della CPU nello scambio tra modalità kernel e modalità utente, il che comporta ulteriori cicli macchina.

&nbsp;
&nbsp;
&nbsp;

*Driver del Dispositivo*
====

Abbiamo fin qui analizzato che cosa fanno i controller dei dispositivi. Abbiamo visto che ciascun controller utilizza alcuni registri dei dispositivi per inviare comandi o leggere il proprio stato o entrambe le cose. Il numero di questi registri e la natura dei comandi varia da dispositivo a dispositivo. Per esempio, un driver di un mouse deve accettare informazioni dal mouse che indichino di quanto si è mosso e quali pulsanti sono attualmente premuti. Diversamente un driver di un disco dovrà sapere tutto riguardo a settori, tracce, cilindri, spostamento della testina, motori, tempi di fermo delle testine e tutti gli altri meccanismi che consentono al disco di operare correttamente. Questi driver ovviamente saranno molto ­diversi.

Di conseguenza ciascun dispositivo di I/O connesso al computer necessita di un certo codice specifico al suo controllo. Questo codice, il driver di dispositivo (device driver), è solitamente scritto dal produttore del dispositivo stesso e rilasciato insieme a esso. Dato che ogni sistema operativo necessita dei propri driver, i produttori generalmente forniscono driver per gran parte dei sistemi operativi più conosciuti.

Ogni driver del dispositivo gestisce normalmente un tipo di dispositivo o al massimo una classe di dispositivi strettamente correlati. Per esempio, un driver per dischi SCSI può solitamente gestire più dischi SCSI di diverse dimensioni e diverse velocità e altrettanto bene anche un Blu-ray SCSI. D’altra parte, un mouse e un joystick sono talmente diversi che solitamente sono richiesti driver differenti. Non c’è tuttavia una restrizione tecnica sul fatto che un driver controlli più dispositivi molto diversi fra loro; semplicemente non è una buona idea nella maggior parte dei casi.

A volte, però, driver profondamente diversi sono basati sulla stessa tecnologia. L’esempio più noto è quello dell’USB, una tecnologia basata su bus seriali che non a caso viene detta “universale”. Fra i dispositivi USB si trovano dischi, chiavette di memoria, fotocamere, mouse, tastiere, ventilatori, schede di rete wireless, robot, lettori di carte, rasoi ricaricabili, distruggidocumenti, lettori di codici a barre, sfere specchiate e termometri portatili. Tutti questi dispositivi utilizzano USB eppure svolgono compiti totalmente diversi. Il trucco è che i driver USB sono disposti su uno stack, come accade per lo stack TCP/IP delle reti. Alla base, solitamente nell’hardware, si trova il livello di collegamento USB (I/O seriale) che gestisce questioni hard-ware come la segnalazione e la decodifica dei flussi di segnali in pacchetti USB; viene utilizzato dai livelli superiori che hanno a che fare con i pacchetti dati e con le funzionalità comuni condivise dalla maggior parte dei dispositivi USB. Al di sopra di tutto si trovano infine le API di alto livello, come le interfacce per le memorie di massa, le fotocamere ecc. I driver di dispositivo sono pertanto diversi, anche se condividono una parte dello stack dei protocolli.

Il driver del dispositivo, quanto meno con le attuali architetture, deve normalmente essere parte del kernel del sistema operativo, nell’ottica di poter accedere all’hardware del dispositivo, il che significa accedere ai registri del controller. Effettivamente è possibile costruire driver eseguiti nello spazio utente, con chiamate di sistema per eseguire la lettura e la scrittura dei registri dei dispositivi. Questa progettazione isola il kernel dai driver e i driver l’uno dall’altro, eliminando gran parte delle cause di crash del sistema – driver difettosi che in un modo o nell’altro interferiscono con il kernel. Questa è la direzione da seguire per la realizzazione di sistemi ad alta affidabilità. Un esempio di sistema in cui i driver dei dispositivi sono eseguiti come procedure utente è il MINIX 3 (www.minix3.org). Tuttavia, dato che la maggior parte degli altri sistemi operativi desktop richiede l’esecuzione dei driver nel kernel, questo è il modello che considereremo in questa sede.

Dato che i progettisti di ogni sistema operativo sanno che vi saranno installati dei pezzi di codice (i driver) scritti da terzi, il sistema operativo deve avere un’architettura che consenta queste installazioni. Ciò comporta l’esistenza di un modello ben definito di quello che fa un driver e di come interagisce con il resto del sistema operativo. I driver di dispositivo si posizionano normalmente sotto il resto del sistema operativo, come illustrato nella Figura 5.12. I sistemi operativi solitamente classificano i driver all’interno di un ristretto numero di categorie. Le categorie più comuni sono i dispositivi a blocchi (block device), come i dischi, contenenti molteplici blocchi di dati indirizzabili indipendentemente e i dispositivi a carattere (character device), come stampanti e tastiere, che generano o accettano un flusso di caratteri. La maggior parte dei sistemi operativi definisce un’interfaccia standard che deve essere supportata da tutti i dispositivi a blocchi e una seconda interfaccia standard che deve essere supportata da tutti i dispositivi a carattere. Queste interfacce sono composte da alcune procedure che il resto del sistema operativo può richiamare affinché il driver faccia il suo lavoro. Sono procedure tipiche quelle che leggono un blocco (dispositivo a blocchi) o scrivono un carattere (dispositivo a caratteri).



Posizionamento logico dei driver dei dispositivi. In realtà tutte le comunicazioni tra i driver e i controller dei dispositivi avvengono sul bus.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-12.png)

In alcuni sistemi il sistema operativo è un singolo programma binario contenente compilati al suo interno tutti i driver di cui ha bisogno. Questo schema è stato per anni la norma dei sistemi UNIX, poiché erano eseguiti da centri di elaborazione e da dispositivi che cambiavano raramente. Se veniva aggiunto un dispositivo nuovo l’amministratore del sistema ricompilava semplicemente il kernel con il nuovo driver, per costruire un nuovo ­binario. Con l’avvento dei personal computer, con le loro miriadi di dispositivi di I/O, questo modello smise di funzionare. Pochi utenti sono in grado di ricompilare o di ricomporre il kernel, anche se hanno il codice sorgente o i moduli oggetto, il che non sempre è vero. I sistemi operativi invece, a partire dall’MS-DOS, andarono nella direzione in cui i driver erano caricati dinamicamente nel sistema durante l’esecuzione. Sistemi diversi gestiscono il caricamento dei driver in modi diversi.

Un driver di dispositivo ha molte funzioni. La più ovvia è accettare richieste di scrittura e lettura astratte provenienti dal software indipendente dal dispositivo sopra di esso e vedere che vengano portate a termine. Ma esiste anche un minimo di altre funzioni che esso deve eseguire. Il driver per esempio se necessario deve inizializzare il dispositivo. Può anche doverne gestire i requisiti di alimentazione e il registro degli eventi.

Molti dispositivi hanno una struttura generale simile fra loro. Un driver classico parte verificando se i parametri di input sono validi o meno. Se non lo sono, è restituito un errore. Se sono validi potrebbe rendersi necessaria una traduzione in termini pratici, a partire dall’astratto. Per il driver di un disco questo potrebbe significare la conversione del numero di un blocco lineare nei numeri di testina, traccia, settore e cilindro della geometria del ­disco.

In seguito il driver potrebbe verificare se il dispositivo sia attualmente in uso. Se lo fosse la richiesta andrebbe in coda per un’elaborazione successiva. Se il dispositivo è inattivo verrà esaminato lo stato dell’hardware per vedere se la richiesta può essere gestita immediatamente. Una volta che il dispositivo è acceso e pronto a partire, può iniziare il controllo effettivo.

Controllare il dispositivo significa inviargli una serie di comandi. Il driver è il luogo dove si determina la sequenza di comandi, a seconda di cosa deve essere fatto. Una volta che il driver sa quali comandi sta per inviare, inizia a scriverli nei registri del dispositivo del controller. Dopo la scrittura di ciascun comando nel controller, potrebbe rendersi neces­sario verificare se il controller abbia accettato il comando e sia pronto ad accettare il successivo; questa sequenza continua finché non sono stati inviati tutti i comandi. Ad alcuni controller può essere data una lista collegata di comandi (in memoria) e detto loro di leggerli e processarli tutti per proprio conto, senza alcun ulteriore aiuto dal sistema ­operativo.

Dopo l’invio di ciascun comando si verificheranno due possibili situazioni. In molti casi il driver del dispositivo deve aspettare finché il controller non ha eseguito un po’ di lavoro, così si blocca finché non arriva un interrupt a sbloccarlo. In altri casi, invece, l’operazione finisce senza ritardo e quindi il driver non ha bisogno di bloccarsi. Come esempio di quest’ultima situazione, lo scorrere dello schermo in modalità carattere richiede la scrittura di pochi byte all’interno dei registri del controller. Non ci sono meccanismi in movimento e pertanto l’intera operazione si può svolgere in qualche nanosecondo.

Nel primo caso, il driver bloccato sarà risvegliato tramite l’interrupt; nell’ultimo caso non si “addormenterà” mai. In entrambi casi, dopo il completamento dell’operazione, il driver deve controllare eventuali errori. Se tutto è a posto, il driver potrebbe dover passare dei dati (per esempio un blocco appena letto) al software indipendente dal dispositivo. Alla fine restituirà alcune informazioni di stato, per fare il rapporto degli errori al chiamante. Se ci sono in coda altre richieste, ne può essere selezionata e avviata una. In caso contrario il driver si blocca in attesa della richiesta successiva.

Questo semplice modello è solo una grossolana approssimazione della realtà. Molti fattori rendono il codice molto più complicato. Innanzitutto, un dispositivo di I/O potrebbe terminare mentre è in esecuzione un driver, interrompendolo. L’interrupt potrebbe causare l’esecuzione di un driver di dispositivo. In effetti, potrebbe causare l’esecuzione del driver attuale. Per esempio, mentre il driver della rete sta processando un pacchetto in ingresso, potrebbe giungere un altro pacchetto. Di conseguenza, i driver dovrebbero essere rientranti, ossia un driver in esecuzione deve aspettarsi di essere chiamato una seconda volta prima che sia completata la prima.

In un sistema “a caldo” (hot pluggable system), i dispositivi possono essere aggiunti o rimossi con il sistema funzionante. Di conseguenza, mentre un driver è occupato nella lettura di un dispositivo, il sistema può informarlo che l’utente ha rimosso improvvisamente quel dispositivo dal sistema.

Non solo l’attuale trasferimento di I/O deve essere annullato senza danneggiare alcuna struttura dati del kernel, ma deve anche essere gar­batamente rimossa qualunque altra richiesta del dispositivo svanito e ai loro chiamanti de­ve essere data la brutta notizia. Inoltre, l’aggiunta inaspettata di nuovi dispositivi può ­costringere il kernel a fare giochi di prestigio con le risorse (per esempio, gli IRQ), togliendone di vecchie dal driver e assegnandogliene di nuove al loro posto. Ai driver non sono consentite chiamate di sistema, che però hanno spesso bisogno di interagire con il resto del kernel. Di solito le chiamate a determinate procedure kernel sono permesse. Per esempio, ci sono spesso chiamate per posizionare e riposizionare pagine di memoria fisica (hardwired) da usare come buffer. Altre chiamate utili sono necessarie per gestire l’MMU, i timer, il controller DMA, i controller degli interrupt e così via.

&nbsp;
&nbsp;
&nbsp;

*Software per l’I/O indipendente dal dispositivo*
====

Sebbene parte del software per l’I/O sia specifico di un determinato dispositivo, altre parti sono indipendenti dal dispositivo stesso (device independent). Il limite esatto fra i driver e il software indipendente dal dispositivo dipende dal sistema e dal dispositivo, poiché alcune funzioni che potrebbero essere svolte in modalità indipendente dal dispositivo sono effettivamente svolte dai driver, sia per efficienza sia per altre ragioni. Le funzioni mostrate nella Figura 5.13 sono eseguite tipicamente da software indipendente dal dispositivo.



Funzioni del software per l’I/O indipendente dai dispositivi.

| Funzioni                                           	|
|-----------------------------------------------------	|
| Interfacciamento uniforme dei driver dei dispostivi 	|
| Buffering                                           	|
| Segnalazione degli errori                           	|
| Allocazione e rilascio dei dispositivi dedicati     	|
| Dimensione dei blocchi indipendente dai dispositivi 	|

La funzione base del software indipendente dal dispositivo è quella di eseguire tutte quelle funzioni di I/O trasversali a tutti i dispositivi e di fornire un’interfaccia uniforme al software a livello utente. Di seguito analizzeremo nel dettaglio tutte le funzioni sopraddette.

&nbsp;
&nbsp;
&nbsp;

    Interfacciamento uniforme dei driver dei dispositivi

Una questione fondamentale di un sistema operativo è come rendere tutti i dispositivi e i driver più o meno simili tra loro. Se dischi, stampanti, tastiere e così via sono tutti interfacciati ogni volta in modo diverso, ogni volta che arriva un nuovo dispositivo il sistema operativo va modificato. Dover intaccare il sistema operativo per ogni dispositivo nuovo non è una buona idea.

Un aspetto della questione è l’interfaccia fra i driver di dispositivo e il resto del sistema operativo. Nella Figura 5.14(a) è illustrata una situazione in cui ogni driver ha una diversa interfaccia verso il sistema operativo. Quello che significa è che le funzioni dei driver a disposizione del sistema per essere chiamate sono diverse da driver a driver. Potrebbe anche significare che le funzioni del kernel di cui il driver ha bisogno sono diverse da driver a driver. Nel complesso significa che l’interfacciamento di ogni nuovo driver richiede un grande sforzo di programmazione.


(a) Senza un’interfaccia dei driver standard. (b) Con un’interfaccia dei driver standard.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-14.png)

Diversamente, nella Figura 5.14(b) è illustrato un diverso modello in cui tutti i driver hanno la stessa interfaccia. È molto più semplice perciò inserire un nuovo driver, facendo in modo che sia conforme alla loro interfaccia. Significa, inoltre, che chi scrive i driver conosce che cosa ci si aspetta da lui. In pratica, non tutti i dispositivi sono assolutamente identici, ma di solito vi è solo un ristretto numero di tipi di dispositivi e questi generalmente non cambiano.

Il relativo funzionamento è descritto di seguito. Per ciascuna classe di dispositivi, come dischi o stampanti, il sistema operativo definisce un insieme di funzioni che il driver deve supportare. Per un disco queste includeranno la lettura e la scrittura, ma anche l’accensione e lo spegnimento, la formattazione e altre azioni specifiche di un disco. Spesso il driver contiene una tabella con i puntatori a se stesso per queste funzioni. Una volta caricato il driver, il sistema operativo registra l’indirizzo di questa tabella di puntatori di funzioni, così quando ha bisogno di chiamarne una può fare una chiamata indiretta tramite questa tabella. Questa tabella di puntatori di funzioni definisce l’interfaccia fra il driver e il resto del sistema operativo. Tutti i dispositivi di una determinata classe (dischi, stampanti, e così via) devono tenerla in considerazione.

Un altro aspetto dell’uniformità di un’interfaccia riguarda la denominazione dei dispositivi di I/O. Il software indipendente dal dispositivo si prende cura di mappare i nomi simbolici dei dispositivi nel driver adatto. Per esempio, in UNIX un nome di dispositivo, come /dev/disk0, specifica in modo univoco l’i-node per un file speciale e questo i-node contiene il major device number (numero di dispositivo primario), usato per localizzare il driver adeguato. L’i-node contiene anche il minor device number (numero di dispositivo secondario), passato come un parametro al driver al fine di specificare l’unità da leggere o da scrivere. Tutti i dispositivi hanno un numero di dispositivo primario e secondario e l’accesso a tutti i driver avviene selezionandoli usando il numero di dispositivo primario.

Strettamente correlata alla questione dei nomi è la protezione. Come fa il sistema a prevenire l’accesso di utenti a dispositivi a cui non sono autorizzati? Sia in UNIX sia in Windows i dispositivi appaiono nel file system con nomi di oggetti, il che significa che le regole di protezione abituali per i file si applicano anche ai dispositivi di I/O. L’amministratore di sistema può impostare i permessi adeguati per ciascun dispositivo.

&nbsp;
&nbsp;
&nbsp;

    Buffering

Per una varietà di ragioni, anche il buffering costituisce un problema, sia per i dispositivi a blocchi sia per quelli a caratteri. Consideriamo un processo che voglia leggere dei dati da un modem. Una possibile strategia per gestire i caratteri in ingresso consiste nell’avere un processo utente che esegue una chiamata di sistema read e si blocca in attesa di un carattere. Ogni carattere in arrivo causa un interrupt. La procedura di servizio degli interrupt pre­senta il carattere al processo utente e si sblocca. Dopo aver messo il carattere da ­qualche parte, il processo legge un altro carattere e si blocca di nuovo. Questo modello è indicato nella Figu­ra 5.15(a).


(a) Input senza uso di buffer. (b) Uso di buffer nello spazio utente. (c) Uso di buffer nello spazio del kernel seguito dalla copia nello spazio utente. (d) Doppio buffer nel kernel.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-15.png)

Il problema che sorge da questo schema è che il processo utente deve essere riavviato a ogni carattere in ingresso. Consentire che un processo sia eseguito più volte per brevi periodi non è efficiente e quindi questo schema non è quello valido.

Un miglioramento è mostrato dalla Figura 5.15(b). In questo caso il processo fornisce un buffer di n caratteri nello spazio utente e fa una lettura di n caratteri. La procedura di servizio degli interrupt mette i caratteri in ingresso in questo buffer finché non è pieno. Solo a quel punto risveglia il processo utente. Questo schema è molto più efficiente del precedente, ma ha un rovescio della medaglia: che accade se il buffer viene paginato in uscita all’arrivo di un carattere? Il buffer potrebbe essere bloccato in memoria, ma se molti processi iniziano a bloccare le pagine in memoria, l’insieme di pagine disponibili si restringerebbe con un conseguente calo delle prestazioni.

Un ulteriore approccio è creare un buffer all’interno del kernel e avere il gestore degli interrupt che vi mette i caratteri, come mostrato nella Figura 5.15(c). Quando questo buffer è pieno, la pagina con il buffer utente è portata dentro, se necessario, e il buffer copiato in una sola operazione. Questo schema è di gran lunga più efficiente.

Tuttavia anche qui sorge un problema: che accade ai caratteri che arrivano mentre la pagina con il buffer utente viene letta dal disco? Dato che il buffer è pieno, non c’è posto dove metterli. Una via d’uscita è avere un secondo buffer nel kernel. Dopo che si ­riempie il primo, ma prima che sia stato svuotato, si utilizza il secondo, come nella Figura 5.15(d). Al riempirsi del secondo lo si copia in quello utente (dando per scontato che l’utente lo abbia richiesto). Durante questa fase con il secondo buffer, il primo è riusato con i nuovi caratteri. In questo modo i due buffer fanno a turno: mentre uno viene usato per copiare nello spazio utente, l’altro accumula i nuovi input. Uno schema di buffering di questo genere è detto buffering doppio.

Un’altra forma di buffering usata diffusamente è detta buffer circolare. È composta da una zona di memoria e due puntatori, uno dei quali punta alla parola libera successiva, dove poter mettere i nuovi dati, mentre l’altro punta alla prima parola dei dati nel buffer che non è stata ancora rimossa. In molte situazioni l’hardware fa avanzare il primo puntatore a mano a mano che aggiunge nuovi dati (per esempio appena arrivati dalla rete) e il sistema operativo fa avanzare il secondo puntatore a mano a mano che rimuove i dati e li elabora. Entrambi i puntatori vanno avanti e indietro, tornando in fondo quando hanno raggiunto la cima.

L’uso di un buffer è importante anche in fase di output. Consideriamo per esem­pio come viene fatto l’output su un modem senza buffering usando il modello della Figu­ra 5.15(b). Il processo utente esegue una chiamata di sistema write per fare l’output di n caratteri. A questo punto il sistema ha due possibilità. Può bloccare l’utente finché siano stati scritti tutti i caratteri, ma ciò potrebbe richiedere davvero molto tempo su di una linea telefonica lenta. Po­treb­be anche rilasciare immediatamente l’utente e gestire l’I/O mentre l’utente calcola qualcos’altro, ma questo causa un problema forse peggiore: come fa il processo utente a sapere che l’output è stato completato e che può riutilizzare il buffer? Il sistema potrebbe generare un segnale o un interrupt software, ma questo stile di programmazione è difficile e incline alle cosiddette race condition (cioè dipendenti dagli ordini degli accessi). Una soluzione decisamente migliore per il kernel è quella di copiare i dati in un buffer del kernel, analogamente a quanto mostrato nella Figura 5.15(c) (ma nell’altra direzione) e sbloccare immediatamente il chiamante. A questo punto non importa quando l’I/O effettivo è stato completato. L’utente è libero di riutilizzare il buffer nel momento in cui è sbloccato.

Il buffering è una tecnica largamente usata, ma ha anch’essa una controindicazione: se i dati sono messi troppe volte nel buffer, ne soffrono le prestazioni. Consideriamo per esempio la rete della Figura 5.16. In questo caso un utente fa una chiamata di sistema per scrivere sulla rete. Il kernel copia il pacchetto in un buffer del kernel per permettere all’utente di procedere immediatamente (passo 1). A questo punto il programma utente può riusare il buffer.


La trasmissione sulla rete può determinare molte copie di un pacchetto di dati.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-16.png)

Quando è chiamato il driver, esso copia il pacchetto al controller per l’output (passo 2). Il motivo per cui non esegue l’output direttamente dalla memoria del kernel è che, una volta avviata una trasmissione a pacchetti, deve continuare a velocità uniforme. Il driver non può garantire di poter andare in memoria a velocità uniforme, poiché i canali DMA e altri dispositivi di I/O possono rubare molti cicli. Non riuscire a prendere una parola in tempo rovinerebbe il pacchetto. Mettendo il pacchetto nel buffer del controller si evita il problema.

Dopo che il pacchetto è stato copiato nel buffer interno del controller, è copiato sulla rete (passo 3). I bit arrivano al destinatario rapidamente dopo il loro invio, così appena dopo che l’ultimo bit è stato spedito quel bit raggiunge il destinatario, dove il pacchetto è stato bufferizzato nel controller. Il pacchetto è poi copiato nel buffer del kernel del destinatario (passo 4). Infine è copiato nel buffer del processo ricevente (passo 5). Di solito a quel punto il destinatario restituisce un avviso. Quando il mittente lo riceve è pronto a inviare il pacchetto successivo. Dovrebbe essere tuttavia evidente che tutte queste operazioni di copia rallentano considerevolmente la velocità di trasmissione a causa di tutti i passaggi che devono avvenire sequenzialmente.

&nbsp;
&nbsp;
&nbsp;

    Segnalazione degli errori

Gli errori sono molto più frequenti nel contesto dell’I/O che in altri. Quando accadono, il sistema operativo deve gestirli meglio che può. Molti errori sono specifici del dispositivo e devono essere gestiti tramite un driver appropriato, ma la struttura per la loro gestione è indipendente dal dispositivo.

Una classe di errori di I/O è quella degli errori di programmazione. Questi si verifica­no quando un processo richiede qualcosa di impossibile, come la scrittura su un dispositivo di input (tastiera, scanner, mouse, e così via) o la lettura da un dispositivo di output (stampante, plotter, e così via). Altri errori sono fornire un indirizzo di buffer non valido o altri parametri e specificare un dispositivo errato (per esempio il disco 3 mentre il sistema ha solo due dischi) e così via. L’azione da intraprendere in questo caso è semplice: riportare un codice d’errore al chiamante.

Un’altra classe di errori è quella degli errori effettivi di I/O, per esempio un tentativo di scrittura su un blocco danneggiato di un disco o provare a leggere da una videocamera che è stata spenta. In questi casi sta al driver decidere che cosa fare. Se il driver non sa che cosa fare, il problema passa alla parte di software indipendente dal dispositivo.

Quello che questo software fa dipende dalla natura dell’errore e dall’ambiente. Se è un semplice errore di lettura e c’è un utente interattivo disponibile, può visualizzare una finestra di dialogo con la richiesta all’utente sul da farsi. Le opzioni possono includere il riprovare un certo numero di volte, ignorare l’errore o terminare il processo chiamante. Se non vi è un utente disponibile, probabilmente l’unica possibilità reale è che la chiamata di sistema fallisca riportando un codice d’errore.

Alcuni errori tuttavia non possono essere gestiti in questo modo. Per esempio, potrebbe essere andata distrutta una struttura dati critica, come la directory principale o la lista dei blocchi liberi. In questo caso il sistema potrebbe dover visualizzare un messaggio d’errore e terminare.

&nbsp;
&nbsp;
&nbsp;

    Allocazione e rilascio dei dispositivi dedicati

Alcuni dispositivi, come i masterizzatori di CD-ROM, possono essere usati solo da un singolo processo in un determinato momento. Sta al sistema operativo esaminare le richieste per l’uso del dispositivo e accettarle o rifiutarle, a seconda che il dispositivo richiesto sia disponibile o meno. Un modo semplice per gestire queste richieste è di richiedere ai processi di fare la open direttamente su file speciali per i dispositivi. La chiusura di tali dispositivi dedicati rilascia i file.

Un approccio alternativo è quello di avere meccanismi speciali per richiedere e rilasciare dispositivi dedicati. Un tentativo di acquisizione di un dispositivo che non è disponibile blocca il chiamante invece che fallire. I processi bloccati sono messi in una coda. Prima o poi il dispositivo richiesto sarà disponibile e il primo processo della coda potrà acquisirlo e continuare l’esecuzione.

&nbsp;
&nbsp;
&nbsp;

    Dimensione dei blocchi indipendente dal dispositivo

Dischi differenti possono avere settori di diverse dimensioni. Sta al software indipendente dal dispositivo nascondere questo aspetto e fornire una dimensione di blocco uniforme ai livelli più in alto, per esempio trattando molti settori come un blocco logico singolo. In questo modo i livelli più alti hanno a che fare solo con dispositivi astratti, che useranno la stessa dimensione di blocco logico, indipendente dalla dimensione del settore fisico. Similmente, alcuni dispositivi a caratteri forniscono i dati un carattere alla volta (per esempio i modem), mentre altri li consegnano a unità più grandi (per esempio le interfacce di rete). Anche queste differenze possono essere celate.

&nbsp;
&nbsp;
&nbsp;

*Software per l’I/O indipendente dal dispositivo*
====

Sebbene la maggior parte del software di I/O risieda nel sistema operativo, una piccola parte è composta da librerie collegate con i programmi utente e anche da interi programmi eseguiti al di fuori del kernel. Le chiamate di sistema, incluse quelle per l’I/O, sono normalmente eseguite da procedure di libreria. Quando un programma in C contiene la chiamata

```
count=write(fd, buffer, nbytes);
```

la procedura di libreria write sarà collegata con il programma e contenuta nel programma binario presente in memoria durante l’esecuzione. La raccolta di tutte queste procedure di librerie è chiaramente parte del sistema di I/O.

Mentre queste procedure fanno poco altro che mettere i loro parametri nel posto opportuno per la chiamata di sistema, vi sono altre procedure di I/O che svolgono a tutti gli effetti il lavoro reale. In particolare la formattazione dell’input e dell’output è svolta dalle procedure di libreria. Un esempio tratto dal C è printf, che prende una stringa di formato ed eventualmente alcune variabili come input, costruisce una stringa ASCII e poi richiama write per eseguire l’output della stringa. Come esempio di printf si consideri il comando

```
printf("Il quadrato di %3d è %6d\n", i, i*i);
```

Esso formatta una stringa di 15 caratteri “Il quadrato di ” seguita dal valore i come stringa di 3 caratteri, poi la stringa di 3 caratteri “ è ”, poi i2 per 6 caratteri e alla fine il carattere “nuova riga” (line feed).

Un esempio di una procedura simile per l’input è scanf, che legge l’input e lo memorizza nelle variabili descritte in un formato stringa usando la stessa sintassi di printf. La libreria standard di I/O contiene un numero di procedure che coinvolgono l’I/O e che vengono tutte eseguite come parti dei programmi utenti.

Non tutto il software di I/O a livello utente è composto da procedure di libreria. Un’altra categoria importante è quella del sistema di spooling. Lo spooling è il modo di interagire con i dispositivi dedicati in un sistema multiprogrammato. Consideriamo un dispositivo tipico che fa uso di spooling: una stampante. Sebbene sarebbe tecnicamente semplice permettere a qualunque processo di aprire il file speciale a caratteri per la stampante, supponiamo che un processo lo apra e poi non faccia nulla per ore. Nessun altro processo potrebbe stampare.

Quello che viene fatto, invece, è creare un altro processo speciale, chiamato demone (daemon) e una directory speciale, chiamata directory di spooling. Per stampare un file, un processo prima genera l’intero file da stampare e lo mette nella directory di spooling. È poi compito del demone, che è l’unico processo con il permesso di usare il file speciale della stampante, stampare i file nella directory. Con la protezione del file speciale dall’uso diretto degli utenti si elimina il problema che vi sia qualcuno che lo tenga aperto a lungo senza che sia necessario.

Lo spooling non è usato solo nelle stampanti, ma anche in altre situazioni di I/O. Per esempio, il trasferimento di file su una rete usa spesso un demone di rete. Per spedire un file da qualche parte un utente lo mette in una directory di spooling della rete e in seguito il demone della rete lo prende e lo trasmette. Un particolare uso della trasmissione di file in spooling è il sistema USENET News (ora parte di Google Groups). Questa rete è composta da milioni di macchine sparse per il globo che comunicano tramite Internet. Esistono migliaia di newsgroup su molti argomenti. Per pubblicare un nuovo messaggio l’utente richiama un programma di news che accetta che il messaggio sia postato e lo deposita quindi in una directory di spooling per la successiva trasmissione alle altre macchine. La Figura 5.17 sintetizza il sistema di I/O, mostrando tutti i livelli e le principali funzioni di ciascuno. Partendo dal basso, i livelli sono l’hardware, i gestori degli interrupt, i driver dei dispositivi, il software indipendente dai dispositivi e infine i processi utente.



Livelli del sistema di I/O e principali funzioni di ogni livello.

![alt text](https://mediaserver.pearsonitalia.it/mediaserver_uni/books/prod/2017/9788891901026_TANENBAUM/EPUB/ASSETS/images/05-17.png)

Le frecce nella Figura 5.17 mostrano il flusso di controllo. Quando per esempio un programma utente prova a leggere un blocco da un file, il sistema operativo viene richiamato per realizzare la chiamata. Il software indipendente dal dispositivo, per esempio, cerca il blocco nella cache del buffer. Se il blocco non è lì, richiama il driver del dispositivo per inviare la richiesta all’hardware di prelevarlo dal disco. Il processo è poi bloccato sino al completamento dell’operazione del disco.

Quando il disco ha finito, l’hardware genera un interrupt. Il gestore degli interrupt è eseguito per scoprire che cos’è accaduto, ossia quale dispositivo richiede attenzione immediata. Estrae quindi lo stato dal dispositivo e risveglia il processo dormiente per concludere la richiesta di I/O e permettere al processo utente di proseguire.



